# –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã Interview Assistant v0.51

*–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: 5 —Å–µ–Ω—Ç—è–±—Ä—è 2025*  
*–í–µ—Ä—Å–∏—è: v0.51*  
*–°—Ç–∞—Ç—É—Å: –ê–∫—Ç–∏–≤–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞*

---

## üìã **–û–ë–ó–û–† –°–ò–°–¢–ï–ú–´**

Interview Assistant - —ç—Ç–æ Electron-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è HR-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤, –∫–æ—Ç–æ—Ä–æ–µ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ—Ä–≤—å—é, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é AI –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∏–Ω—Å–∞–π—Ç—ã –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π.

### **–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**
- **Electron Main Process** - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–∫–Ω–∞–º–∏ –∏ IPC
- **React Renderer** - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- **Deepgram API** - —Ä–µ—á–µ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
- **Claude AI** - –∞–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤
- **Post-Editor** - –∫–æ—Ä—Ä–µ–∫—Ü–∏—è ASR –æ—à–∏–±–æ–∫
- **RAG System** - –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑

---

## üöÄ **–ü–†–û–¶–ï–°–° –ó–ê–ü–£–°–ö–ê –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø**

### **1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Electron**

**–§–∞–π–ª:** `src/main/main.ts`

```typescript
// –°–æ–±—ã—Ç–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app.whenReady().then(() => {
  createControlPanelWindow();    // –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–Ω–µ–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
  registerGlobalShortcuts();     // –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≥–æ—Ä—è—á–∏—Ö –∫–ª–∞–≤–∏—à
  setupIPC();                    // –ù–∞—Å—Ç—Ä–æ–π–∫–∞ IPC handlers
});
```

**–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å:**
1. `createControlPanelWindow()` - —Å–æ–∑–¥–∞–µ—Ç –≥–ª–∞–≤–Ω–æ–µ –æ–∫–Ω–æ
2. `registerGlobalShortcuts()` - —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç Ctrl+\ –¥–ª—è –ø–æ–∫–∞–∑–∞/—Å–∫—Ä—ã—Ç–∏—è
3. `setupIPC()` - –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç IPC –∫–∞–Ω–∞–ª—ã

### **2. –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–Ω–µ–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è**

```typescript
function createControlPanelWindow() {
  const windowOptions = {
    width: 200, height: 56,           // –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä
    frame: false,                     // –ë–µ–∑ —Å–∏—Å—Ç–µ–º–Ω–æ–π —Ä–∞–º–∫–∏
    transparent: true,                // –ü—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ñ–æ–Ω
    alwaysOnTop: true,                // –ü–æ–≤–µ—Ä—Ö –≤—Å–µ—Ö –æ–∫–æ–Ω
    skipTaskbar: true,                // –ù–µ –≤ –ø–∞–Ω–µ–ª–∏ –∑–∞–¥–∞—á
    webPreferences: {
      nodeIntegration: false,         // ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û
      contextIsolation: true,         // ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û
      webSecurity: true,              // ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û
      preload: path.join(__dirname, '..', 'preload', 'preload.js')
    }
  };
  
  controlPanelWindow = new BrowserWindow(windowOptions);
  controlPanelWindow.loadURL('http://localhost:5173?window=control');
}
```

### **3. –ó–∞–≥—Ä—É–∑–∫–∞ React –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è**

**–§–∞–π–ª:** `src/App.tsx`

```typescript
export function App() {
  // –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ–∫–Ω–∞ –∏–∑ URL –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
  const urlParams = new URLSearchParams(window.location.search);
  const windowType = urlParams.get('window') || 'control';
  
  // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ö—É–∫–∏
  const transcription = useTranscription();
  const audioRecording = useAudioRecording();
  
  // –†–µ–Ω–¥–µ—Ä–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
  if (windowType === 'data') {
    return <DataWindow {...props} />;
  }
  return <ControlPanel {...props} />;
}
```

---

## üé§ **–ü–†–û–¶–ï–°–° –ó–ê–ü–ò–°–ò –ò –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–ò**

### **1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø–∏—Å–∏**

**–§–∞–π–ª:** `src/hooks/useTranscription.ts`

```typescript
const startRecording = useCallback(async () => {
  // –®–ê–ì 1: –û–±–Ω–æ–≤–ª—è–µ–º UI —Å–æ—Å—Ç–æ—è–Ω–∏–µ
  setIsRecording(true);
  
  // –®–ê–ì 2: –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
  const audioConstraints = configService.getAudioConstraints();
  const stream = await navigator.mediaDevices.getUserMedia(audioConstraints);
  
  // –®–ê–ì 3: –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Deepgram
  const cleanup = await connectToDeepgram();
  
  // –®–ê–ì 4: –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∞—É–¥–∏–æ pipeline
  const audioContext = new AudioContext({ sampleRate: 16000 });
  await audioContext.audioWorklet.addModule('/audioWorklet.js');
  
  const source = audioContext.createMediaStreamSource(stream);
  const workletNode = new AudioWorkletNode(audioContext, 'pcm-processor');
  
  // –®–ê–ì 5: –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö
  workletNode.port.onmessage = (event) => {
    if (event.data.type === 'pcm-data') {
      deepgramRef.current.sendAudio(event.data.data);
    }
  };
  
  source.connect(workletNode);
}, []);
```

### **2. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Deepgram**

**–§–∞–π–ª:** `src/services/deepgram.ts`

```typescript
connect(): Promise<void> {
  return new Promise((resolve, reject) => {
    // –°—Ç—Ä–æ–∏–º WebSocket URL —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    const params = new URLSearchParams({
      model: this.config.model,                    // nova-2-meeting
      punctuation: this.config.punctuation.toString(),
      interim_results: this.config.interim_results.toString(),
      smart_format: this.config.smart_format.toString(),
      encoding: 'linear16',
      sample_rate: '16000',
      channels: '1'
    });
    
    const wsUrl = `wss://api.deepgram.com/v1/listen?${params}`;
    this.ws = new WebSocket(wsUrl, ['token', this.config.apiKey]);
    
    this.ws.onopen = () => {
      console.log('‚úÖ WebSocket connected');
      this.startHeartbeat();  // –ó–∞–ø—É—Å–∫–∞–µ–º heartbeat
      resolve();
    };
    
    this.ws.onmessage = async (event) => {
      const data = JSON.parse(event.data);
      
      if (data.channel?.alternatives?.[0]?.transcript) {
        const transcript = data.channel.alternatives[0].transcript.trim();
        const confidence = data.channel.alternatives[0].confidence || 0;
        const is_final = data.is_final || false;
        
        // –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        const analysis = this.adaptiveASR.analyzeTranscript(transcript, confidence, latency);
        
        // –°–æ–∑–¥–∞–µ–º —Å–æ–±—ã—Ç–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
        const transcriptEvent = {
          type: is_final ? 'final' : 'partial',
          text: transcript,
          confidence,
          timestamp: Date.now(),
          segment_id: `segment_${++this.segmentCounter}_${Date.now()}`
        };
        
        // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ
        this.onTranscript(transcriptEvent);
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ—Å—Ç—å –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
        if (this.postEditor && is_final && confidence < 0.8) {
          this.correctSegmentAsync(transcript, analysis, segmentId, confidence);
        }
      }
    };
  });
}
```

### **3. –ê—É–¥–∏–æ Pipeline**

**–§–∞–π–ª:** `public/audioWorklet.js`

```javascript
class PCMProcessor extends AudioWorkletProcessor {
  process(inputs, outputs, parameters) {
    const input = inputs[0];
    if (input.length > 0) {
      const inputData = input[0];
      
      // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Float32 –≤ Int16
      const pcm16 = new Int16Array(inputData.length);
      for (let i = 0; i < inputData.length; i++) {
        pcm16[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
      }
      
      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ main thread
      this.port.postMessage({
        type: 'pcm-data',
        data: pcm16.buffer
      });
    }
    return true;
  }
}

registerProcessor('pcm-processor', PCMProcessor);
```

---

## ü§ñ **–ü–†–û–¶–ï–°–° –ê–ù–ê–õ–ò–ó–ê –° CLAUDE AI**

### **1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Claude —Å–µ—Ä–≤–∏—Å–∞**

**–§–∞–π–ª:** `src/services/claude.ts`

```typescript
export class ClaudeAnalysisService {
  constructor(config: ClaudeServiceConfig, ragService?: RAGService) {
    this.anthropic = new Anthropic({ apiKey: config.apiKey });
    this.systemPrompt = `You are an expert technical interviewer...`;
  }
  
  async analyzeTranscript(request: AnalysisRequest): Promise<InsightResponse> {
    // –£–ª—É—á—à–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é RAG
    let enhancedRequest = request;
    if (this.ragService) {
      const ragContext = await this.ragService.getRelevantContext(
        request.transcript, 
        { types: ['job_description', 'resume'], maxTokens: 2000 }
      );
      enhancedRequest = { ...request, ragContext };
    }
    
    const userPrompt = this.buildUserPrompt(enhancedRequest);
    
    const response = await this.anthropic.messages.create({
      model: this.config.model,           // claude-sonnet-4-20250514
      max_tokens: this.config.maxTokens,  // 300
      temperature: this.config.temperature, // 0.3
      system: this.systemPrompt,
      messages: [{ role: 'user', content: userPrompt }]
    });
    
    return JSON.parse(response.content[0].text);
  }
}
```

### **2. –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑**

**–§–∞–π–ª:** `src/services/claude.ts`

```typescript
private buildUserPrompt(request: AnalysisRequest): string {
  let prompt = `ANALYZE THIS INTERVIEW SEGMENT:

CURRENT TRANSCRIPT:
"${request.transcript}"

CONTEXT WINDOW (last 15-40s):
${request.contextWindow.join(' ')}

TECHNICAL ENTITIES MENTIONED:
${request.entities.join(', ') || 'None yet'}

PREVIOUS TOPICS:
${request.topicHistory.join(', ') || 'None yet'}`;

  // –î–æ–±–∞–≤–ª—è–µ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
  if (request.ragContext?.relevantChunks.length > 0) {
    prompt += `\n\nRELEVANT CONTEXT FROM DOCUMENTS:`;
    
    const jobDescChunks = request.ragContext.relevantChunks.filter(
      chunk => chunk.source.type === 'job_description'
    );
    const resumeChunks = request.ragContext.relevantChunks.filter(
      chunk => chunk.source.type === 'resume'
    );
    
    if (jobDescChunks.length > 0) {
      prompt += `\n\nJOB REQUIREMENTS:`;
      jobDescChunks.forEach((chunk, index) => {
        prompt += `\n${index + 1}. ${chunk.content.substring(0, 500)}...`;
      });
    }
  }
  
  return prompt;
}
```

### **3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ Claude**

**–§–∞–π–ª:** `src/hooks/useTranscription.ts`

```typescript
const analyzeWithClaude = useCallback(async (newText: string): Promise<void> => {
  if (!claudeRef.current || !analysisContextRef.current) return;
  
  // –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
  analysisContextRef.current.addTranscript(newText);
  const context = analysisContextRef.current.getContext();
  
  const analysisRequest = {
    transcript: newText,
    contextWindow: context.contextWindow,
    entities: context.entities,
    topicHistory: context.topicHistory
  };
  
  // –ü–æ–ª—É—á–∞–µ–º –∞–Ω–∞–ª–∏–∑ –æ—Ç Claude
  const analysis: InsightResponse = await claudeRef.current.analyzeTranscript(analysisRequest);
  
  // –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ø–∏–∫ –≤ –∏—Å—Ç–æ—Ä–∏—é
  analysisContextRef.current.addTopic(analysis.topic);
  
  // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ legacy —Ñ–æ—Ä–º–∞—Ç –¥–ª—è UI
  const legacyInsight: LegacyInsight = {
    id: Date.now().toString(),
    text: analysis.note,
    type: analysis.type  // 'strength' | 'risk' | 'question'
  };
  
  // –û–±–Ω–æ–≤–ª—è–µ–º UI (–ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 insights)
  setInsights(prev => [...prev.slice(-2), legacyInsight]);
}, []);
```

---

## üîß **–ü–†–û–¶–ï–°–° –ö–û–†–†–ï–ö–¶–ò–ò ASR**

### **1. –ê–Ω–∞–ª–∏–∑ —Å–µ–≥–º–µ–Ω—Ç–∞**

**–§–∞–π–ª:** `src/services/post-editor.ts`

```typescript
analyzeSegment(text: string, confidence: number): SegmentAnalysis {
  const analysis: SegmentAnalysis = {
    needsCorrection: false,
    reasons: [],
    confidence: 0,
    language: this.detectLanguage(text),
    technicalTerms: this.extractTechnicalTerms(text)
  };
  
  // –¢—Ä–∏–≥–≥–µ—Ä—ã –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
  if (confidence < 0.7) {
    analysis.needsCorrection = true;
    analysis.reasons.push('low_confidence');
  }
  
  if (analysis.language === 'mixed') {
    analysis.needsCorrection = true;
    analysis.reasons.push('mixed_language');
  }
  
  if (analysis.technicalTerms.length > 0) {
    analysis.needsCorrection = true;
    analysis.reasons.push('technical_terms');
  }
  
  const suspiciousWords = this.findSuspiciousWords(text);
  if (suspiciousWords.length > 0) {
    analysis.needsCorrection = true;
    analysis.reasons.push('suspicious_words');
  }
  
  return analysis;
}
```

### **2. –î–µ—Ç–µ–∫—Ü–∏—è —è–∑—ã–∫–∞**

```typescript
private detectLanguage(text: string): 'ru' | 'en' | 'mixed' {
  const cyrillicPattern = /[–∞-—è—ë]/i;
  const latinPattern = /[a-z]/i;
  
  const hasCyrillic = cyrillicPattern.test(text);
  const hasLatin = latinPattern.test(text);
  
  if (hasCyrillic && hasLatin) return 'mixed';
  if (hasCyrillic) return 'ru';
  return 'en';
}
```

### **3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤**

```typescript
private extractTechnicalTerms(text: string): string[] {
  const patterns = [
    /\b[A-Z][a-z]*[A-Z][a-zA-Z]*\b/g,  // CamelCase
    /\b\w+\.(js|ts|py|java|go|rs|sql|json|yaml|yml|xml|html|css)\b/g, // Extensions
    /\b(API|SDK|UI|UX|DB|SQL|REST|GraphQL|JWT|OAuth|HTTP|HTTPS|JSON|XML|HTML|CSS|NPM|Git|Docker|Kubernetes|AWS|Azure|GCP)\b/g, // Tech acronyms
    /\b[a-z]+\-[a-z\-]+\b/g,  // kebab-case
    /\b[a-z_]+_[a-z_]+\b/g,   // snake_case
    /\bv?\d+\.\d+(\.\d+)?(\-[a-z0-9\-]+)?(\+[a-z0-9\-]+)?\b/g, // –í–µ—Ä—Å–∏–∏
  ];
  
  const terms: string[] = [];
  patterns.forEach(pattern => {
    const matches = text.match(pattern);
    if (matches) terms.push(...matches);
  });
  
  return [...new Set(terms)];
}
```

### **4. LLM –∫–æ—Ä—Ä–µ–∫—Ü–∏—è**

```typescript
async correctText(text: string, analysis: SegmentAnalysis): Promise<CorrectionResult> {
  const startTime = Date.now();
  
  try {
    // Rate limiting
    await this.enforceRateLimit();
    
    const systemPrompt = this.buildSystemPrompt();
    const userPrompt = this.buildUserPrompt(text, analysis);
    
    const response = await Promise.race([
      this.anthropic.messages.create({
        model: this.config.model,        // claude-3-haiku-20240307
        max_tokens: this.config.maxTokens, // 150
        temperature: this.config.temperature, // 0.1
        system: systemPrompt,
        messages: [{ role: 'user', content: userPrompt }]
      }),
      this.createTimeoutPromise(this.config.timeoutMs) // 500ms
    ]);
    
    const result = JSON.parse(response.content[0].text);
    
    return {
      correctedText: result.corrected_text,
      wasChanged: result.was_changed,
      confidence: result.confidence,
      processingTimeMs: Date.now() - startTime
    };
    
  } catch (error) {
    // –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
    return {
      correctedText: text,
      wasChanged: false,
      confidence: 0,
      processingTimeMs: Date.now() - startTime
    };
  }
}
```

---

## ü™ü **–ü–†–û–¶–ï–°–° –£–ü–†–ê–í–õ–ï–ù–ò–Ø –û–ö–ù–ê–ú–ò**

### **1. –°–æ–∑–¥–∞–Ω–∏–µ –æ–∫–Ω–∞ –¥–∞–Ω–Ω—ã—Ö**

**–§–∞–π–ª:** `src/main/main.ts`

```typescript
function createDataWindow() {
  if (dataWindow && !dataWindow.isDestroyed()) {
    dataWindow.show();
    dataWindow.focus();
    return;
  }
  
  const dataWindowOptions = {
    width: 600, height: 400,
    frame: false,                    // –ë–µ–∑ —Å–∏—Å—Ç–µ–º–Ω–æ–π —Ä–∞–º–∫–∏
    transparent: true,               // –ü—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ñ–æ–Ω
    alwaysOnTop: true,
    skipTaskbar: true,               // –ù–µ –≤ –ø–∞–Ω–µ–ª–∏ –∑–∞–¥–∞—á
    show: false,                     // –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å—Ä–∞–∑—É
    webPreferences: {
      nodeIntegration: false,        // ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û
      contextIsolation: true,        // ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û
      webSecurity: true,             // ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û
      preload: path.join(__dirname, '..', 'preload', 'preload.js')
    }
  };
  
  dataWindow = new BrowserWindow(dataWindowOptions);
  dataWindow.loadURL('http://localhost:5173?window=data');
  
  // –ü–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä—É–µ–º —Ä—è–¥–æ–º —Å –ø–∞–Ω–µ–ª—å—é —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
  if (controlPanelWindow) {
    const panelBounds = controlPanelWindow.getBounds();
    dataWindow.setPosition(panelBounds.x, panelBounds.y + panelBounds.height + 10);
  }
  
  // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—á–µ—Ä–µ–¥—å –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –æ–∫–Ω–∞
  processPendingData();
}
```

### **2. IPC Handlers**

```typescript
function setupIPC() {
  // –°–æ–∑–¥–∞—Ç—å –æ–∫–Ω–æ —Å –¥–∞–Ω–Ω—ã–º–∏
  ipcMain.handle('create-data-window', () => {
    try {
      createDataWindow();
      if (controlPanelWindow) {
        controlPanelWindow.webContents.send('window-created', 'data');
      }
      return { success: true, message: 'Data window creation initiated' };
    } catch (error) {
      return { success: false, error: error.message };
    }
  });
  
  // –ü–µ—Ä–µ–¥–∞—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –≤ –æ–∫–Ω–æ –¥–∞–Ω–Ω—ã—Ö
  ipcMain.handle('send-transcript', (event, data) => {
    if (dataWindow && !dataWindow.isDestroyed()) {
      dataWindow.webContents.send('transcript-update', data);
    } else {
      pendingTranscriptData.push(data); // –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
    }
  });
  
  // –ü–µ—Ä–µ–¥–∞—Ç—å –∏–Ω—Å–∞–π—Ç—ã –≤ –æ–∫–Ω–æ –¥–∞–Ω–Ω—ã—Ö
  ipcMain.handle('send-insights', (event, insights) => {
    if (dataWindow && !dataWindow.isDestroyed()) {
      dataWindow.webContents.send('insights-update', insights);
    } else {
      pendingInsightsData.push(insights);
    }
  });
}
```

### **3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—á–µ—Ä–µ–¥–∏ –¥–∞–Ω–Ω—ã—Ö**

```typescript
function processPendingData() {
  if (!dataWindow || dataWindow.isDestroyed()) return;
  
  // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
  pendingTranscriptData.forEach(data => {
    dataWindow.webContents.send('transcript-update', data);
  });
  pendingTranscriptData = [];
  
  // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–Ω—Å–∞–π—Ç–æ–≤
  pendingInsightsData.forEach(data => {
    dataWindow.webContents.send('insights-update', data);
  });
  pendingInsightsData = [];
  
  // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∑–∞–ø–∏—Å–∏
  pendingRecordingStateData.forEach(data => {
    dataWindow.webContents.send('recording-state-change', data);
  });
  pendingRecordingStateData = [];
}
```

---

## üîÑ **–ü–†–û–¶–ï–°–° –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–ò –î–ê–ù–ù–´–•**

### **1. Preload Script**

**–§–∞–π–ª:** `src/preload/preload.ts`

```typescript
contextBridge.exposeInMainWorld('electronAPI', {
  // –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã
  getConfig: () => Promise.resolve({ 
    audio: { sampleRate: 16000 }, 
    ui: { theme: 'dark' },
    env: {
      DEEPGRAM_API_KEY: process.env.DEEPGRAM_API_KEY || '',
      CLAUDE_API_KEY: process.env.CLAUDE_API_KEY || '',
      OPENAI_API_KEY: process.env.OPENAI_API_KEY || '',
      POST_EDITOR_API_KEY: process.env.POST_EDITOR_API_KEY || '',
      NODE_ENV: process.env.NODE_ENV || 'development'
    }
  }),
  
  // IPC –º–µ—Ç–æ–¥—ã
  sendTranscript: (data: any) => ipcRenderer.invoke('send-transcript', data),
  sendInsights: (data: any) => ipcRenderer.invoke('send-insights', data),
  sendRecordingState: (data: any) => ipcRenderer.invoke('send-recording-state', data),
  createDataWindow: () => ipcRenderer.invoke('create-data-window'),
  closeDataWindow: () => ipcRenderer.invoke('close-data-window'),
  
  // –°–ª—É—à–∞—Ç–µ–ª–∏ —Å–æ–±—ã—Ç–∏–π
  onTranscriptUpdate: (callback: (data: any) => void) => {
    const handler = (event: any, data: any) => callback(data);
    ipcRenderer.on('transcript-update', handler);
    return () => ipcRenderer.removeListener('transcript-update', handler);
  },
  
  onInsightsUpdate: (callback: (data: any) => void) => {
    const handler = (event: any, data: any) => callback(data);
    ipcRenderer.on('insights-update', handler);
    return () => ipcRenderer.removeListener('insights-update', handler);
  }
});
```

### **2. Data Sync Hook**

**–§–∞–π–ª:** `src/hooks/useDataSync.ts`

```typescript
export const useDataSync = (options: DataSyncOptions) => {
  const { windowType, transcript, partialTranscript, insights, isRecording } = options;
  
  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –æ–∫–Ω–æ —Å –¥–∞–Ω–Ω—ã–º–∏
  const sendToDataWindow = useCallback((type: 'transcript' | 'insights' | 'recording-state', data: any) => {
    if (window.electronAPI && windowType !== 'data') {
      if (type === 'transcript') {
        window.electronAPI.sendTranscript(data);
      } else if (type === 'insights') {
        window.electronAPI.sendInsights(data);
      } else if (type === 'recording-state') {
        window.electronAPI.sendRecordingState(data.isRecording);
      }
    }
  }, [windowType]);
  
  // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏
  useEffect(() => {
    if (windowType === 'control' && transcript !== undefined) {
      sendToDataWindow('transcript', { transcript, partialTranscript });
    }
  }, [transcript, partialTranscript, windowType, sendToDataWindow]);
  
  useEffect(() => {
    if (windowType === 'control' && insights !== undefined) {
      sendToDataWindow('insights', insights);
    }
  }, [insights, windowType, sendToDataWindow]);
  
  // –°–ª—É—à–∞—Ç–µ–ª–∏ —Å–æ–±—ã—Ç–∏–π –¥–ª—è data –æ–∫–Ω–∞
  useEffect(() => {
    if (windowType === 'data' && window.electronAPI) {
      let cleanupTranscript: (() => void) | undefined;
      let cleanupInsights: (() => void) | undefined;
      
      if (onTranscriptUpdate) {
        cleanupTranscript = window.electronAPI.onTranscriptUpdate(onTranscriptUpdate);
      }
      
      if (onInsightsUpdate) {
        cleanupInsights = window.electronAPI.onInsightsUpdate(onInsightsUpdate);
      }
      
      return () => {
        if (cleanupTranscript) cleanupTranscript();
        if (cleanupInsights) cleanupInsights();
      };
    }
  }, [windowType, onTranscriptUpdate, onInsightsUpdate]);
  
  return { sendToDataWindow };
};
```

---

## ‚öôÔ∏è **–ü–†–û–¶–ï–°–° –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò**

### **1. Config Service**

**–§–∞–π–ª:** `src/services/config.ts`

```typescript
class ConfigService {
  private config: AppConfig;
  
  constructor() {
    this.config = this.loadConfig();
    this.validateConfig();
  }
  
  private loadConfig(): AppConfig {
    return {
      api: {
        deepgram: {
          apiKey: this.getEnvVar('DEEPGRAM_API_KEY', ''),
          model: 'nova-2-meeting',           // –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è —Å–æ–≤–µ—â–∞–Ω–∏–π
          language: '',                       // –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
          punctuation: true,                  // –í–∫–ª—é—á–µ–Ω–∞
          interimResults: true,               // –í–∫–ª—é—á–µ–Ω—ã
          smartFormat: true,                  // –í–∫–ª—é—á–µ–Ω
          endpointing: 800,                   // 800ms –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ñ—Ä–∞–∑—ã
          vadEvents: true,                    // Voice Activity Detection
          noDelay: true,                      // –£–±—Ä–∞–Ω–∞ –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—è
          interimResultsPeriod: 100,          // 100ms –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–∫–ª–∏–∫–∞
          keywords: this.getDefaultKeywords() // IT-—Ç–µ—Ä–º–∏–Ω—ã
        },
        claude: {
          apiKey: this.getEnvVar('CLAUDE_API_KEY', ''),
          model: 'claude-sonnet-4-20250514',
          maxTokens: 300,
          temperature: 0.3
        },
        postEditor: {
          apiKey: this.getEnvVar('POST_EDITOR_API_KEY', ''),
          model: 'claude-3-haiku-20240307',  // –ë—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å
          maxTokens: 150,
          temperature: 0.1,                   // –ù–∏–∑–∫–∞—è –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
          maxRequestsPerSecond: 3,            // Rate limiting
          timeoutMs: 500,                     // –¢–∞–π–º–∞—É—Ç
          enabled: true
        }
      },
      audio: {
        sampleRate: 16000,
        channels: 1,
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true,
        chunkSize: 250
      },
      ui: {
        insightFrequencyMs: 3000,
        minInsightConfidence: 0.6,
        transcriptBufferWords: 600,
        maxInsightsDisplay: 3,
        defaultActivePanel: 'transcript',
        defaultClickThrough: false
      },
      isDevelopment: this.getEnvVar('NODE_ENV', 'development') === 'development'
    };
  }
  
  // –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è
  async getConfigWithEnv(): Promise<AppConfig> {
    if (typeof window !== 'undefined' && (window as any).electronAPI) {
      try {
        const configData = await (window as any).electronAPI.getConfig();
        if (configData?.env) {
          // –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è
          this.config.api.deepgram.apiKey = configData.env.DEEPGRAM_API_KEY || this.config.api.deepgram.apiKey;
          this.config.api.claude.apiKey = configData.env.CLAUDE_API_KEY || this.config.api.claude.apiKey;
          this.config.api.openai.apiKey = configData.env.OPENAI_API_KEY || this.config.api.openai.apiKey;
          this.config.api.postEditor.apiKey = configData.env.POST_EDITOR_API_KEY || this.config.api.postEditor.apiKey;
          this.config.isDevelopment = configData.env.NODE_ENV === 'development';
        }
      } catch (error) {
        console.warn('‚ö†Ô∏è Failed to load environment variables from electronAPI:', error);
      }
    }
    return this.config;
  }
}
```

### **2. Vite Configuration**

**–§–∞–π–ª:** `vite.config.js`

```javascript
export default defineConfig({
  plugins: [react()],
  base: './',
  
  server: {
    port: 5173,
    strictPort: true,
    host: 'localhost'
  },
  
  resolve: {
    alias: {
      '@': resolve(__dirname, 'src'),
      '@/types': resolve(__dirname, 'src/types'),
      '@/components': resolve(__dirname, 'src/components'),
      '@/hooks': resolve(__dirname, 'src/hooks'),
      '@/services': resolve(__dirname, 'src/services')
    }
  },
  
  // –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (TODO: –ü–µ—Ä–µ–Ω–µ—Å—Ç–∏ –≤ preload –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)
  define: {
    __APP_VERSION__: JSON.stringify(process.env.npm_package_version || '0.1.0'),
    __NODE_ENV__: JSON.stringify(process.env.NODE_ENV || 'development'),
    
    // API Keys
    'process.env.DEEPGRAM_API_KEY': JSON.stringify(process.env.DEEPGRAM_API_KEY || ''),
    'process.env.CLAUDE_API_KEY': JSON.stringify(process.env.CLAUDE_API_KEY || ''),
    
    // Deepgram Settings
    'process.env.DEEPGRAM_MODEL': JSON.stringify(process.env.DEEPGRAM_MODEL || 'nova-2'),
    'process.env.DEEPGRAM_LANGUAGE': JSON.stringify(process.env.DEEPGRAM_LANGUAGE || 'ru'),
    
    // Claude Settings
    'process.env.CLAUDE_MODEL': JSON.stringify(process.env.CLAUDE_MODEL || 'claude-sonnet-4-20250514'),
    'process.env.CLAUDE_MAX_TOKENS': JSON.stringify(process.env.CLAUDE_MAX_TOKENS || '300'),
    'process.env.CLAUDE_TEMPERATURE': JSON.stringify(process.env.CLAUDE_TEMPERATURE || '0.3'),
    
    // Audio Settings
    'process.env.AUDIO_SAMPLE_RATE': JSON.stringify(process.env.AUDIO_SAMPLE_RATE || '16000'),
    'process.env.AUDIO_CHANNELS': JSON.stringify(process.env.AUDIO_CHANNELS || '1'),
    'process.env.AUDIO_ECHO_CANCELLATION': JSON.stringify(process.env.AUDIO_ECHO_CANCELLATION || 'true'),
    'process.env.AUDIO_NOISE_SUPPRESSION': JSON.stringify(process.env.AUDIO_NOISE_SUPPRESSION || 'true'),
    'process.env.AUDIO_AUTO_GAIN_CONTROL': JSON.stringify(process.env.AUDIO_AUTO_GAIN_CONTROL || 'true'),
    'process.env.AUDIO_CHUNK_SIZE': JSON.stringify(process.env.AUDIO_CHUNK_SIZE || '250')
  }
});
```

---

## üß† **–ê–î–ê–ü–¢–ò–í–ù–ê–Ø –°–ò–°–¢–ï–ú–ê ASR**

### **1. –î–µ—Ç–µ–∫—Ü–∏—è —è–∑—ã–∫–∞**

**–§–∞–π–ª:** `src/services/adaptive-asr.ts`

```typescript
export class LanguageDetector {
  detectLanguage(text: string): LanguageStats {
    const englishPattern = /[a-zA-Z]/g;
    const russianPattern = /[–∞-—è—ë]/gi;
    const numberPattern = /\d/g;
    
    const englishChars = (text.match(englishPattern) || []).length;
    const russianChars = (text.match(russianPattern) || []).length;
    const numberChars = (text.match(numberPattern) || []).length;
    
    const totalLetters = englishChars + russianChars;
    const totalChars = text.length - numberChars;
    
    if (totalLetters === 0) {
      return { language: 'mixed', confidence: 0.5, characterCount: totalChars, lastDetected: Date.now() };
    }
    
    const englishRatio = englishChars / totalLetters;
    const russianRatio = russianChars / totalLetters;
    
    let detectedLanguage: 'ru' | 'en' | 'mixed';
    let confidence: number;
    
    if (englishRatio > 0.8) {
      detectedLanguage = 'en';
      confidence = englishRatio;
    } else if (russianRatio > 0.8) {
      detectedLanguage = 'ru';
      confidence = russianRatio;
    } else {
      detectedLanguage = 'mixed';
      confidence = 1 - Math.abs(englishRatio - russianRatio);
    }
    
    return { language: detectedLanguage, confidence, characterCount: totalChars, lastDetected: Date.now() };
  }
  
  // –ü–æ–ª—É—á–∏—Ç—å –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π —è–∑—ã–∫ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã
  getDominantLanguage(): 'ru' | 'en' | 'mixed' {
    if (this.languageHistory.length === 0) return 'mixed';
    
    const recent = this.languageHistory.slice(-5); // –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    const langCounts = { ru: 0, en: 0, mixed: 0 };
    
    recent.forEach(stats => {
      langCounts[stats.language]++;
    });
    
    const dominant = Object.entries(langCounts).reduce((a, b) => 
      langCounts[a[0]] > langCounts[b[0]] ? a : b
    )[0] as 'ru' | 'en' | 'mixed';
    
    return dominant;
  }
}
```

### **2. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**

```typescript
export class PerformanceOptimizer {
  updateMetrics(confidence: number, latency: number, hadError: boolean = false) {
    this.metrics.totalSegments++;
    
    // –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (—ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ)
    this.metrics.avgConfidence = this.metrics.avgConfidence * 0.9 + confidence * 0.1;
    
    // –û–±–Ω–æ–≤–ª—è–µ–º –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å
    this.latencyHistory.push(latency);
    if (this.latencyHistory.length > 20) {
      this.latencyHistory = this.latencyHistory.slice(-20);
    }
    this.metrics.avgLatency = this.latencyHistory.reduce((a, b) => a + b) / this.latencyHistory.length;
    
    // –û–±–Ω–æ–≤–ª—è–µ–º —á–∞—Å—Ç–æ—Ç—É –æ—à–∏–±–æ–∫
    if (hadError) {
      this.metrics.errorRate = this.metrics.errorRate * 0.95 + 0.05;
    } else {
      this.metrics.errorRate = this.metrics.errorRate * 0.95;
    }
  }
  
  // –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
  getModelRecommendation(): { model: string, reason: string } {
    const sessionTime = (Date.now() - this.metrics.sessionStartTime) / (1000 * 60);
    
    if (sessionTime > 30 && this.metrics.avgConfidence < 0.7) {
      return { model: 'nova-2-general', reason: 'low confidence in long session' };
    }
    
    if (this.metrics.avgConfidence > 0.9 && this.metrics.avgLatency > 300) {
      return { model: 'base', reason: 'high confidence, optimize for speed' };
    }
    
    if (this.metrics.errorRate > 0.2) {
      return { model: 'nova-2', reason: 'high error rate, need accuracy' };
    }
    
    return { model: 'nova-2-meeting', reason: 'balanced for interview context' };
  }
  
  // –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è Deepgram
  getAdaptiveParameters(): {
    endpointing: number,
    interim_results_period: number,
    confidence_threshold: number
  } {
    let endpointing = 300;
    if (this.metrics.avgConfidence < 0.7) {
      endpointing = 500; // –ñ–¥–µ–º –¥–æ–ª—å—à–µ –ø—Ä–∏ –Ω–∏–∑–∫–æ–º –∫–∞—á–µ—Å—Ç–≤–µ
    } else if (this.metrics.avgConfidence > 0.9) {
      endpointing = 200; // –ë—ã—Å—Ç—Ä–µ–µ –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–º –∫–∞—á–µ—Å—Ç–≤–µ
    }
    
    let interimPeriod = 100;
    if (this.metrics.avgLatency > 400) {
      interimPeriod = 200; // –†–µ–∂–µ –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–π –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
    } else if (this.metrics.avgLatency < 150) {
      interimPeriod = 50; // –ß–∞—â–µ –ø—Ä–∏ –Ω–∏–∑–∫–æ–π –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
    }
    
    let confidenceThreshold = 0.9;
    if (this.metrics.avgConfidence < 0.8) {
      confidenceThreshold = 0.85; // –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è
    } else if (this.metrics.avgConfidence > 0.95) {
      confidenceThreshold = 0.95; // –ë–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è
    }
    
    return { endpointing, interim_results_period: interimPeriod, confidence_threshold: confidenceThreshold };
  }
}
```

### **3. –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä ASR**

```typescript
export class AdaptiveASRManager {
  private languageDetector: LanguageDetector;
  private performanceOptimizer: PerformanceOptimizer;
  private currentLanguageSetting: string = 'multi';
  
  analyzeTranscript(text: string, confidence: number, latency: number = 200): {
    languageStats: LanguageStats,
    shouldOptimize: boolean,
    recommendations: {
      languageSwitch?: { switch: boolean, newSetting: string },
      modelSwitch?: { model: string, reason: string },
      adaptiveParams?: any
    }
  } {
    const languageStats = this.languageDetector.detectLanguage(text);
    this.performanceOptimizer.updateMetrics(confidence, latency);
    
    const languageSwitch = this.languageDetector.shouldSwitchModel(this.currentLanguageSetting);
    const modelRecommendation = this.performanceOptimizer.getModelRecommendation();
    const adaptiveParams = this.performanceOptimizer.getAdaptiveParameters();
    
    const shouldOptimize = languageSwitch.switch || 
                          modelRecommendation.model !== 'nova-2-meeting' ||
                          adaptiveParams.confidence_threshold !== 0.9;
    
    return {
      languageStats,
      shouldOptimize,
      recommendations: {
        languageSwitch: languageSwitch.switch ? languageSwitch : undefined,
        modelSwitch: modelRecommendation,
        adaptiveParams
      }
    };
  }
}
```

---

## üìä **–ü–†–û–¶–ï–°–° –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø**

### **1. Transcript Logger**

**–§–∞–π–ª:** `src/services/transcript-logger.ts`

```typescript
export class TranscriptLogger {
  private sessionId: string;
  private logDir: string;
  private logFile: string;
  private sessionStartTime: number;
  
  constructor() {
    this.sessionId = `session_${new Date().toISOString().replace(/[:.]/g, '-').slice(0, 19)}`;
    this.logDir = path.join(process.cwd(), 'transcript-logs');
    this.logFile = path.join(this.logDir, `${this.sessionId}.md`);
    this.sessionStartTime = Date.now();
    
    this.ensureLogDirectory();
    this.initializeLogFile();
  }
  
  logTranscript(transcript: TranscriptLogEntry): void {
    const timestamp = new Date(transcript.timestamp).toLocaleTimeString();
    const logEntry = `[${timestamp}] ${transcript.type.toUpperCase()}: ${transcript.text}`;
    
    if (transcript.confidence !== undefined) {
      logEntry += ` (confidence: ${transcript.confidence.toFixed(2)})`;
    }
    
    if (transcript.segment_id) {
      logEntry += ` [${transcript.segment_id}]`;
    }
    
    if (transcript.language) {
      logEntry += ` [lang: ${transcript.language}]`;
    }
    
    if (transcript.original_text) {
      logEntry += `\n  Original: ${transcript.original_text}`;
    }
    
    logEntry += '\n\n';
    
    fs.appendFileSync(this.logFile, logEntry);
  }
  
  endSession(): void {
    const sessionDuration = Date.now() - this.sessionStartTime;
    const durationMinutes = Math.round(sessionDuration / 60000);
    
    const summary = `\n---\n\n## Session Summary\n- Duration: ${durationMinutes} minutes\n- Ended: ${new Date().toISOString()}\n`;
    
    fs.appendFileSync(this.logFile, summary);
  }
}
```

---

## üé® **–ü–†–û–¶–ï–°–° –û–¢–û–ë–†–ê–ñ–ï–ù–ò–Ø UI**


### **1. Control Panel Component**

**–§–∞–π–ª:** `src/components/ControlPanel.tsx`

```typescript
export function ControlPanel({
  isRecording,
  hasPermission,
  transcript,
  partialTranscript,
  insights,
  audioLevel,
  onStartRecording,
  onStopRecording,
  onCheckMicPermission
}: ControlPanelProps) {
  
  // –ï—Å–ª–∏ –∑–∞–ø–∏—Å—å –∏–¥–µ—Ç, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —ç–∫—Ä–∞–Ω –∑–∞–ø–∏—Å–∏
  if (isRecording) {
    return (
      <div className="recording-screen">
        {/* Top panel - recording controls */}
        <div className="recording-screen__header">
          <div className="control-panel control-panel--recording">
            <div className="control-panel__actions">
              {/* Stop button */}
              <button onClick={onStopRecording} className="stop-button">
                <div className="stop-button__icon"></div>
              </button>
              
              {/* Wave Loader Recording indicator */}
              <WaveLoader 
                isActive={true}
                audioLevel={audioLevel}
                className="wave-loader--recording"
              />
            </div>
            
            <div className="control-panel__separator"></div>
            
            {/* Drag zone */}
            <div className="control-panel__drag-zone" style={{WebkitAppRegion: 'drag'}}>
              <div className="drag-dots">
                <div className="drag-dots__dot"></div>
                <div className="drag-dots__dot"></div>
                <div className="drag-dots__dot"></div>
                <div className="drag-dots__dot"></div>
              </div>
            </div>
          </div>
        </div>

        {/* Main content area */}
        <div className="recording-screen__content">
          {/* Transcript section */}
          <div className="transcript-section">
            <div className="transcript-section__header">
              <h3>Transcript</h3>
            </div>
            <div className="transcript-section__content">
              {transcript ? (
                <div className="transcript-text">
                  {transcript}
                  {partialTranscript && (
                    <span className="transcript-text--partial">
                      {partialTranscript}
                    </span>
                  )}
                </div>
              ) : (
                <div className="transcript-placeholder">
                  {partialTranscript || 'Start speaking to see transcript...'}
                </div>
              )}
            </div>
          </div>

          {/* Insights section */}
          {insights.length > 0 && (
            <div className="insights-section">
              <div className="insights-section__header">
                <h3>Insights</h3>
              </div>
              <div className="insights-section__content">
                {insights.map((insight) => (
                  <div 
                    key={insight.id} 
                    className={`insight insight--${insight.type}`}
                  >
                    {insight.text}
                  </div>
                ))}
              </div>
            </div>
          )}
        </div>
      </div>
    );
  }

  // –ï—Å–ª–∏ –Ω–µ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ä—Ç–æ–≤—ã–π —ç–∫—Ä–∞–Ω
  return (
    <div className="w-full h-full flex items-center justify-center">
      <div className="control-panel">
        <div className="control-panel__actions">
          <button
            onClick={() => {
              if (hasPermission) {
                onStartRecording();
              } else {
                onCheckMicPermission();
              }
            }}
            className="start-button"
            style={{WebkitAppRegion: 'no-drag'}}
          >
            <div className="start-button__icon">
              <div className="start-button__icon-rect"></div>
              <svg className="start-button__icon-svg" viewBox="0 0 8 10" fill="none">
                <ellipse cx="4" cy="8" rx="4" ry="2" stroke="white" strokeWidth="1.4"/>
              </svg>
            </div>
            <span>{hasPermission ? 'Start' : 'Allow Mic'}</span>
          </button>
        </div>
        
        <div className="control-panel__separator"></div>
        
        <div className="control-panel__drag-zone" style={{WebkitAppRegion: 'drag'}}>
          <div className="drag-dots">
            <div className="drag-dots__dot"></div>
            <div className="drag-dots__dot"></div>
            <div className="drag-dots__dot"></div>
            <div className="drag-dots__dot"></div>
          </div>
        </div>
      </div>
    </div>
  );
}
```

### **2. Data Window Component**

**–§–∞–π–ª:** `src/components/DataWindow.tsx`

```typescript
export function DataWindow({
  transcript,
  partialTranscript,
  insights,
  isRecording
}: DataWindowProps) {
  return (
    <div className="data-window">
      {/* Header */}
      <div className="data-window__header">
        <h2>Interview Assistant</h2>
        <div className={`recording-indicator ${isRecording ? 'recording-indicator--active' : ''}`}>
          {isRecording ? '‚óè Recording' : '‚óã Stopped'}
        </div>
      </div>

      {/* Transcript section */}
      <div className="data-window__transcript">
        <h3>Transcript</h3>
        <div className="transcript-content">
          {transcript ? (
            <div className="transcript-text">
              {transcript}
              {partialTranscript && (
                <span className="transcript-text--partial">
                  {partialTranscript}
                </span>
              )}
            </div>
          ) : (
            <div className="transcript-placeholder">
              {partialTranscript || 'No transcript yet...'}
            </div>
          )}
        </div>
      </div>

      {/* Insights section */}
      {insights.length > 0 && (
        <div className="data-window__insights">
          <h3>Insights</h3>
          <div className="insights-content">
            {insights.map((insight) => (
              <div 
                key={insight.id} 
                className={`insight insight--${insight.type}`}
              >
                {insight.text}
              </div>
            ))}
          </div>
        </div>
      )}
    </div>
  );
}
```

### **3. Wave Loader Component**

**–§–∞–π–ª:** `src/components/WaveLoader.tsx`

```typescript
export function WaveLoader({ 
  isActive, 
  audioLevel, 
  className 
}: WaveLoaderProps) {
  const [animationPhase, setAnimationPhase] = useState(0);
  
  useEffect(() => {
    if (!isActive) return;
    
    const interval = setInterval(() => {
      setAnimationPhase(prev => (prev + 1) % 4);
    }, 150);
    
    return () => clearInterval(interval);
  }, [isActive]);
  
  return (
    <div className={`wave-loader ${className || ''}`}>
      <div className="wave-loader__bars">
        {[0, 1, 2, 3].map((index) => (
          <div
            key={index}
            className={`wave-loader__bar ${
              isActive && animationPhase === index ? 'wave-loader__bar--active' : ''
            }`}
            style={{
              height: isActive ? `${Math.max(4, audioLevel * 20)}px` : '4px'
            }}
          />
        ))}
      </div>
    </div>
  );
}
```

---

## üîÑ **–ü–†–û–¶–ï–°–° –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–ò –°–û–°–¢–û–Ø–ù–ò–Ø**

### **1. Audio Recording Hook**

**–§–∞–π–ª:** `src/hooks/useAudioRecording.ts`

```typescript
export const useAudioRecording = (): UseAudioRecordingReturn => {
  const [hasPermission, setHasPermission] = useState<boolean>(false);

  const checkMicPermission = useCallback(async () => {
    try {
      console.log('üé§ Checking microphone permission...');
      const audioConstraints = configService.getAudioConstraints();
      const stream = await navigator.mediaDevices.getUserMedia(audioConstraints);
      console.log('‚úÖ Microphone permission granted!');
      setHasPermission(true);
      stream.getTracks().forEach(track => track.stop());
    } catch (error) {
      console.error('‚ùå Microphone permission denied:', error);
      setHasPermission(false);
    }
  }, []);

  return {
    hasPermission,
    setHasPermission,
    checkMicPermission
  };
};
```

### **2. Audio Analyser Hook**

**–§–∞–π–ª:** `src/hooks/useAudioAnalyser.ts`

```typescript
export const useAudioAnalyser = () => {
  const [audioLevel, setAudioLevel] = useState<number>(0);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);

  const initAudioAnalyser = useCallback((stream: MediaStream) => {
    const audioContext = new AudioContext();
    const source = audioContext.createMediaStreamSource(stream);
    const analyser = audioContext.createAnalyser();
    
    analyser.fftSize = 256;
    analyser.smoothingTimeConstant = 0.8;
    
    source.connect(analyser);
    analyserRef.current = analyser;
    
    // –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞
    const analyzeAudio = () => {
      if (!analyserRef.current) return;
      
      const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);
      analyserRef.current.getByteFrequencyData(dataArray);
      
      // –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å
      const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
      setAudioLevel(average / 255); // –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 0-1
      
      animationFrameRef.current = requestAnimationFrame(analyzeAudio);
    };
    
    analyzeAudio();
  }, []);

  const stopAudioAnalyser = useCallback(() => {
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
    analyserRef.current = null;
    setAudioLevel(0);
  }, []);

  return {
    audioLevel,
    initAudioAnalyser,
    stopAudioAnalyser
  };
};
```

---

## üõ°Ô∏è **–ü–†–û–¶–ï–°–° –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò**

### **1. Electron Security Settings**

**–§–∞–π–ª:** `src/main/main.ts`

```typescript
webPreferences: {
  nodeIntegration: false,       // ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û - –æ—Ç–∫–ª—é—á–µ–Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Node.js
  contextIsolation: true,       // ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û - –∏–∑–æ–ª—è—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
  webSecurity: true,            // ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û - –≤–µ–±-–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –≤–∫–ª—é—á–µ–Ω–∞
  backgroundThrottling: false,  // –û—Ç–∫–ª—é—á–∞–µ–º throttling –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
  enableRemoteModule: false,    // –û—Ç–∫–ª—é—á–∞–µ–º remote module
  preload: path.join(__dirname, '..', 'preload', 'preload.js') // Preload script
}
```

### **2. Preload Script Security**

**–§–∞–π–ª:** `src/preload/preload.ts`

```typescript
import { contextBridge, ipcRenderer } from 'electron';

// –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π API –¥–ª—è renderer –ø—Ä–æ—Ü–µ—Å—Å–∞
contextBridge.exposeInMainWorld('electronAPI', {
  // –¢–æ–ª—å–∫–æ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –º–µ—Ç–æ–¥—ã
  getConfig: () => Promise.resolve({ 
    audio: { sampleRate: 16000 }, 
    ui: { theme: 'dark' },
    env: {
      DEEPGRAM_API_KEY: process.env.DEEPGRAM_API_KEY || '',
      CLAUDE_API_KEY: process.env.CLAUDE_API_KEY || '',
      OPENAI_API_KEY: process.env.OPENAI_API_KEY || '',
      POST_EDITOR_API_KEY: process.env.POST_EDITOR_API_KEY || '',
      NODE_ENV: process.env.NODE_ENV || 'development'
    }
  }),
  
  // IPC –º–µ—Ç–æ–¥—ã
  sendTranscript: (data: any) => ipcRenderer.invoke('send-transcript', data),
  sendInsights: (data: any) => ipcRenderer.invoke('send-insights', data),
  sendRecordingState: (data: any) => ipcRenderer.invoke('send-recording-state', data),
  createDataWindow: () => ipcRenderer.invoke('create-data-window'),
  closeDataWindow: () => ipcRenderer.invoke('close-data-window'),
  
  // –°–ª—É—à–∞—Ç–µ–ª–∏ —Å–æ–±—ã—Ç–∏–π
  onTranscriptUpdate: (callback: (data: any) => void) => {
    const handler = (event: any, data: any) => callback(data);
    ipcRenderer.on('transcript-update', handler);
    return () => ipcRenderer.removeListener('transcript-update', handler);
  },
  
  onInsightsUpdate: (callback: (data: any) => void) => {
    const handler = (event: any, data: any) => callback(data);
    ipcRenderer.on('insights-update', handler);
    return () => ipcRenderer.removeListener('insights-update', handler);
  },
  
  onRecordingStateChange: (callback: (data: any) => void) => {
    const handler = (event: any, data: any) => callback(data);
    ipcRenderer.on('recording-state-change', handler);
    return () => ipcRenderer.removeListener('recording-state-change', handler);
  },
  
  onWindowCreated: (callback: (windowId: string) => void) => {
    const handler = (event: any, windowId: string) => callback(windowId);
    ipcRenderer.on('window-created', handler);
    return () => ipcRenderer.removeListener('window-created', handler);
  },
  
  onWindowClosed: (callback: (windowId: string) => void) => {
    const handler = (event: any, windowId: string) => callback(windowId);
    ipcRenderer.on('window-closed', handler);
    return () => ipcRenderer.removeListener('window-closed', handler);
  },
  
  removeAllListeners: (channel: string) => {
    ipcRenderer.removeAllListeners(channel);
  }
  
  // –ù–ï —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º API –∫–ª—é—á–∏ –Ω–∞–ø—Ä—è–º—É—é!
});
```

### **3. Environment Variables Security**

**–ü—Ä–æ–±–ª–µ–º–∞:** API –∫–ª—é—á–∏ –ø–æ–ø–∞–¥–∞—é—Ç –≤ bundle —á–µ—Ä–µ–∑ `vite.config.js`

```javascript
// ‚ùå –ù–ï–ë–ï–ó–û–ü–ê–°–ù–û –≤ vite.config.js
define: {
  'process.env.DEEPGRAM_API_KEY': JSON.stringify(process.env.DEEPGRAM_API_KEY || ''),
  'process.env.CLAUDE_API_KEY': JSON.stringify(process.env.CLAUDE_API_KEY || ''),
}
```

**–†–µ—à–µ–Ω–∏–µ:** –ü–µ—Ä–µ–¥–∞—á–∞ —á–µ—Ä–µ–∑ preload script

```typescript
// ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û –≤ preload.ts
contextBridge.exposeInMainWorld('electronAPI', {
  getConfig: () => Promise.resolve({
    env: {
      DEEPGRAM_API_KEY: process.env.DEEPGRAM_API_KEY || '',
      CLAUDE_API_KEY: process.env.CLAUDE_API_KEY || '',
    }
  })
});
```

---

## üì¶ **–ü–†–û–¶–ï–°–° –°–ë–û–†–ö–ò –ò –†–ê–ó–í–ï–†–¢–´–í–ê–ù–ò–Ø**

### **1. Package.json Scripts**

**–§–∞–π–ª:** `package.json`

```json
{
  "scripts": {
    "dev": "concurrently \"npm run dev:vite\" \"wait-on http://localhost:5173 && npm run dev:electron\"",
    "dev:vite": "vite",
    "dev:electron": "tsc -p tsconfig.main.json && electron dist/main/main/main.js",
    "build": "npm run build:vite && npm run build:electron",
    "build:vite": "vite build",
    "build:electron": "tsc -p tsconfig.main.json",
    "compile-main": "tsc -p tsconfig.main.json",
    "clean": "rimraf dist",
    "type-check": "tsc --noEmit"
  }
}
```

### **2. TypeScript Configuration**

**–§–∞–π–ª:** `tsconfig.main.json`

```json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "target": "ES2020",
    "module": "CommonJS",
    "outDir": "dist/main",
    "rootDir": "src/main",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true
  },
  "include": [
    "src/main/**/*",
    "src/preload/**/*"
  ],
  "exclude": [
    "node_modules",
    "dist",
    "src/renderer"
  ]
}
```

### **3. Vite Build Configuration**

**–§–∞–π–ª:** `vite.config.js`

```javascript
export default defineConfig({
  plugins: [react()],
  base: './',
  
  server: {
    port: 5173,
    strictPort: true,
    host: 'localhost'
  },
  
  resolve: {
    alias: {
      '@': resolve(__dirname, 'src'),
      '@/types': resolve(__dirname, 'src/types'),
      '@/components': resolve(__dirname, 'src/components'),
      '@/hooks': resolve(__dirname, 'src/hooks'),
      '@/services': resolve(__dirname, 'src/services')
    }
  },
  
  build: {
    outDir: 'dist/renderer',
    emptyOutDir: true,
    target: 'esnext',
    minify: process.env.NODE_ENV === 'production',
    sourcemap: process.env.NODE_ENV === 'development'
  },
  
  optimizeDeps: {
    include: ['react', 'react-dom', 'zod']
  }
});
```

---

## üîß **–ü–†–û–¶–ï–°–° –û–¢–õ–ê–î–ö–ò –ò –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê**

### **1. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ Development**

```typescript
// –í–∫–ª—é—á–µ–Ω–∏–µ DevTools –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
if (configService.isDevelopment) {
  console.log('üîß Development mode - logging config...');
  configService.logConfig();
}

// DevTools –¥–ª—è –ø–∞–Ω–µ–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
controlPanelWindow.webContents.once('did-finish-load', () => {
  console.log('üîß Opening DevTools for control panel');
  controlPanelWindow?.webContents.openDevTools({ mode: 'detach' });
});

// DevTools –¥–ª—è –æ–∫–Ω–∞ –¥–∞–Ω–Ω—ã—Ö
dataWindow.webContents.on('did-finish-load', () => {
  console.log('üîß Opening DevTools for data window');
  dataWindow.webContents.openDevTools();
});
```

### **2. –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –≥–æ—Ä—è—á–∏–µ –∫–ª–∞–≤–∏—à–∏**

```typescript
function registerGlobalShortcuts() {
  // Ctrl/Cmd + \ –¥–ª—è –ø–æ–∫–∞–∑–∞/—Å–∫—Ä—ã—Ç–∏—è –ø–∞–Ω–µ–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
  globalShortcut.register('CommandOrControl+\\', () => {
    if (controlPanelWindow) {
      if (controlPanelWindow.isVisible()) {
        controlPanelWindow.hide();
        if (dataWindow) dataWindow.hide();
      } else {
        controlPanelWindow.show();
        controlPanelWindow.focus();
        if (dataWindow) dataWindow.show();
      }
    }
  });

  console.log('Global shortcuts registered');
}
```

### **3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫**

```typescript
// –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∏—Å–∫–ª—é—á–µ–Ω–∏–π
process.on('uncaughtException', (error) => {
  console.error('Uncaught Exception:', error);
});

process.on('unhandledRejection', (reason, promise) => {
  console.error('Unhandled Rejection at:', promise, 'reason:', reason);
});

// –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ WebSocket
this.ws.onerror = (error) => {
  console.error('‚ùå [DEEPGRAM] WebSocket error:', error);
  this.onError('WebSocket connection error');
};

// –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ Claude API
catch (error) {
  console.error('‚ùå Claude analysis error:', error);
  
  // Fallback insight –Ω–∞ –æ—à–∏–±–∫—É
  return {
    topic: 'Analysis Error',
    depth_score: 0,
    signals: ['API error occurred'],
    followups: [],
    note: 'AI analysis temporarily unavailable',
    type: 'risk',
    confidence: 0
  };
}
```

---

## üìã **–ü–û–õ–ù–´–ô –ñ–ò–ó–ù–ï–ù–ù–´–ô –¶–ò–ö–õ –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø**

### **1. –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è**

```
1. npm run dev
   ‚îú‚îÄ‚îÄ npm run dev:vite (–∑–∞–ø—É—Å–∫ Vite —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ :5173)
   ‚îî‚îÄ‚îÄ wait-on http://localhost:5173 && npm run dev:electron
       ‚îú‚îÄ‚îÄ tsc -p tsconfig.main.json (–∫–æ–º–ø–∏–ª—è—Ü–∏—è main –ø—Ä–æ—Ü–µ—Å—Å–∞)
       ‚îî‚îÄ‚îÄ electron dist/main/main/main.js (–∑–∞–ø—É—Å–∫ Electron)

2. app.whenReady()
   ‚îú‚îÄ‚îÄ createControlPanelWindow() (—Å–æ–∑–¥–∞–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–≥–æ –æ–∫–Ω–∞)
   ‚îú‚îÄ‚îÄ registerGlobalShortcuts() (—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è Ctrl+\)
   ‚îî‚îÄ‚îÄ setupIPC() (–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ IPC –∫–∞–Ω–∞–ª–æ–≤)

3. React App –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è
   ‚îú‚îÄ‚îÄ App.tsx –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç windowType –∏–∑ URL
   ‚îú‚îÄ‚îÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è —Ö—É–∫–∏ (useTranscription, useAudioRecording)
   ‚îî‚îÄ‚îÄ –†–µ–Ω–¥–µ—Ä–∏—Ç—Å—è ControlPanel –∏–ª–∏ DataWindow
```

### **2. –ù–∞—á–∞–ª–æ –∑–∞–ø–∏—Å–∏**

```
1. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∂–∏–º–∞–µ—Ç "Start"
   ‚îú‚îÄ‚îÄ onStartRecording() –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è
   ‚îú‚îÄ‚îÄ setIsRecording(true) - –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ UI
   ‚îî‚îÄ‚îÄ setTimeout(() => { ... }, 100) - –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏

2. –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
   ‚îú‚îÄ‚îÄ navigator.mediaDevices.getUserMedia(audioConstraints)
   ‚îú‚îÄ‚îÄ streamRef.current = stream
   ‚îî‚îÄ‚îÄ initAudioAnalyser(stream) - –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞

3. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Deepgram
   ‚îú‚îÄ‚îÄ configService.getConfigWithEnv() - –∑–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
   ‚îú‚îÄ‚îÄ TranscriptionServiceFactory.create() - —Å–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞
   ‚îú‚îÄ‚îÄ deepgram.connect() - WebSocket –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
   ‚îî‚îÄ‚îÄ cleanupRef.current = cleanup - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—á–∏—Å—Ç–∫–∏

4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞—É–¥–∏–æ pipeline
   ‚îú‚îÄ‚îÄ new AudioContext({ sampleRate: 16000 })
   ‚îú‚îÄ‚îÄ audioContext.audioWorklet.addModule('/audioWorklet.js')
   ‚îú‚îÄ‚îÄ new AudioWorkletNode(audioContext, 'pcm-processor')
   ‚îî‚îÄ‚îÄ workletNode.port.onmessage - –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö
```

### **3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏**

```
1. –ê—É–¥–∏–æ –ø–æ—Ç–æ–∫
   ‚îú‚îÄ‚îÄ MediaStream ‚Üí AudioContext ‚Üí AudioWorkletNode
   ‚îú‚îÄ‚îÄ PCMProcessor.process() - –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è Float32 ‚Üí Int16
   ‚îî‚îÄ‚îÄ workletNode.port.postMessage() - –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ main thread

2. Deepgram WebSocket
   ‚îú‚îÄ‚îÄ ws.send(pcm16.buffer) - –æ—Ç–ø—Ä–∞–≤–∫–∞ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö
   ‚îú‚îÄ‚îÄ ws.onmessage - –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
   ‚îú‚îÄ‚îÄ JSON.parse(event.data) - –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞
   ‚îî‚îÄ‚îÄ adaptiveASR.analyzeTranscript() - –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑

3. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
   ‚îú‚îÄ‚îÄ –°–æ–∑–¥–∞–Ω–∏–µ TranscriptEvent (partial/final)
   ‚îú‚îÄ‚îÄ getTranscriptLogger().logTranscript() - –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
   ‚îú‚îÄ‚îÄ this.onTranscript(transcriptEvent) - –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ UI
   ‚îî‚îÄ‚îÄ postEditor.correctText() - –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

4. –ê–Ω–∞–ª–∏–∑ —Å Claude AI
   ‚îú‚îÄ‚îÄ analysisContextRef.current.addTranscript(newText)
   ‚îú‚îÄ‚îÄ claudeRef.current.analyzeTranscript(analysisRequest)
   ‚îú‚îÄ‚îÄ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ LegacyInsight
   ‚îî‚îÄ‚îÄ setInsights(prev => [...prev.slice(-2), legacyInsight])
```

### **4. –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –º–µ–∂–¥—É –æ–∫–Ω–∞–º–∏**

```
1. Control Panel ‚Üí Data Window
   ‚îú‚îÄ‚îÄ useDataSync.sendToDataWindow('transcript', data)
   ‚îú‚îÄ‚îÄ window.electronAPI.sendTranscript(data)
   ‚îú‚îÄ‚îÄ ipcRenderer.invoke('send-transcript', data)
   ‚îî‚îÄ‚îÄ ipcMain.handle('send-transcript') ‚Üí dataWindow.webContents.send()

2. Data Window –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
   ‚îú‚îÄ‚îÄ window.electronAPI.onTranscriptUpdate(callback)
   ‚îú‚îÄ‚îÄ ipcRenderer.on('transcript-update', handler)
   ‚îî‚îÄ‚îÄ onTranscriptUpdate(data) - –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è

3. –û—á–µ—Ä–µ–¥—å –¥–∞–Ω–Ω—ã—Ö
   ‚îú‚îÄ‚îÄ pendingTranscriptData.push(data) - –µ—Å–ª–∏ –æ–∫–Ω–æ –Ω–µ —Å–æ–∑–¥–∞–Ω–æ
   ‚îú‚îÄ‚îÄ processPendingData() - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –æ–∫–Ω–∞
   ‚îî‚îÄ‚îÄ dataWindow.webContents.send() - –æ—Ç–ø—Ä–∞–≤–∫–∞ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
```

### **5. –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏**

```
1. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∂–∏–º–∞–µ—Ç "Stop"
   ‚îú‚îÄ‚îÄ onStopRecording() –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è
   ‚îî‚îÄ‚îÄ –û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö —Ä–µ—Å—É—Ä—Å–æ–≤

2. –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞—É–¥–∏–æ pipeline
   ‚îú‚îÄ‚îÄ processorRef.current.disconnect()
   ‚îú‚îÄ‚îÄ audioContextRef.current.close()
   ‚îî‚îÄ‚îÄ streamRef.current.getTracks().forEach(track => track.stop())

3. –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç Deepgram
   ‚îú‚îÄ‚îÄ cleanupRef.current() - –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—á–∏—Å—Ç–∫–∏
   ‚îú‚îÄ‚îÄ deepgram.disconnect()
   ‚îú‚îÄ‚îÄ this.ws.close()
   ‚îî‚îÄ‚îÄ getTranscriptLogger().endSession()

4. –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
   ‚îú‚îÄ‚îÄ stopAudioAnalyser()
   ‚îî‚îÄ‚îÄ setIsRecording(false) - –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ UI
```

### **6. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è**

```
1. app.on('before-quit')
   ‚îú‚îÄ‚îÄ isQuitting = true
   ‚îú‚îÄ‚îÄ controlPanelWindow.webContents.closeDevTools()
   ‚îú‚îÄ‚îÄ dataWindow.webContents.closeDevTools()
   ‚îú‚îÄ‚îÄ globalShortcut.unregisterAll()
   ‚îî‚îÄ‚îÄ BrowserWindow.getAllWindows().forEach(window => window.destroy())

2. app.on('will-quit')
   ‚îú‚îÄ‚îÄ –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –æ–∫–æ–Ω
   ‚îî‚îÄ‚îÄ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ –≤—Å–µ—Ö –æ–∫–æ–Ω

3. app.on('window-all-closed')
   ‚îî‚îÄ‚îÄ app.quit() - –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
```

---

## üéØ **–ö–õ–Æ–ß–ï–í–´–ï –û–°–û–ë–ï–ù–ù–û–°–¢–ò –ê–†–•–ò–¢–ï–ö–¢–£–†–´**

### **1. –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å**
- ‚úÖ `nodeIntegration: false` - –æ—Ç–∫–ª—é—á–µ–Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Node.js
- ‚úÖ `contextIsolation: true` - –∏–∑–æ–ª—è—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- ‚úÖ `webSecurity: true` - –≤–µ–±-–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
- ‚úÖ Preload script –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –ø–µ—Ä–µ–¥–∞—á–∏ –¥–∞–Ω–Ω—ã—Ö
- ‚úÖ API –∫–ª—é—á–∏ –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ contextBridge

### **2. –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**
- ‚úÖ AudioWorklet –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ
- ‚úÖ –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ ASR
- ‚úÖ Rate limiting –¥–ª—è API –≤—ã–∑–æ–≤–æ–≤
- ‚úÖ –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
- ‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã Deepgram

### **3. –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å**
- ‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –Ω–∞ –≤—Å–µ—Ö —É—Ä–æ–≤–Ω—è—Ö
- ‚úÖ Fallback –º–µ—Ö–∞–Ω–∏–∑–º—ã
- ‚úÖ Heartbeat –¥–ª—è WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
- ‚úÖ –û—á–µ—Ä–µ–¥—å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
- ‚úÖ Graceful shutdown

### **4. –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å**
- ‚úÖ –ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- ‚úÖ –§–∞–±—Ä–∏—á–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —Å–µ—Ä–≤–∏—Å–æ–≤
- ‚úÖ –ê–¥–∞–ø—Ç–µ—Ä—ã –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö API
- ‚úÖ RAG —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- ‚úÖ –ü–ª–∞–≥–∏–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞

---

## üìù **–ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï**

Interview Assistant v0.51 –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Å–ª–æ–∂–Ω—É—é —Å–∏—Å—Ç–µ–º—É —Å –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:

**–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã:**
1. **–ó–∞–ø—É—Å–∫** - Electron + React –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
2. **–ó–∞–ø–∏—Å—å** - –ê—É–¥–∏–æ pipeline + Deepgram WebSocket
3. **–ê–Ω–∞–ª–∏–∑** - Claude AI + RAG —Å–∏—Å—Ç–µ–º–∞
4. **–ö–æ—Ä—Ä–µ–∫—Ü–∏—è** - Post-editor –¥–ª—è ASR –æ—à–∏–±–æ–∫
5. **–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è** - IPC –º–µ–∂–¥—É –æ–∫–Ω–∞–º–∏
6. **–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ** - React –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å —Ä–µ–∞–ª—å–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º

**–ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:**
- **Electron** - –∫—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–æ–µ –¥–µ—Å–∫—Ç–æ–ø–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
- **React** - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- **Deepgram** - —Ä–µ—á–µ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
- **Claude AI** - –∞–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤
- **WebSocket** - —Ä–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
- **AudioWorklet** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ
- **TypeScript** - —Ç–∏–ø–∏–∑–∞—Ü–∏—è

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã:**
- –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ –∏–∑–æ–ª—è—Ü–∏—é –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
- –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã
- –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫
- –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É

–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ production —Å—Ä–µ–¥–µ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.

---

*–î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω: 5 —Å–µ–Ω—Ç—è–±—Ä—è 2025*  
*–í–µ—Ä—Å–∏—è: v0.51*  
*–°—Ç–∞—Ç—É—Å: –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è*nel Component**

**–§–∞–π–ª:** `src/components/ControlPanel.tsx`

```typescript
export function ControlPanel({
  isRecording,
  hasPermission,
  transcript,
  partialTranscript,
  insights,
  audioLevel,
  onStartRecording,
  onStopRecording,
  onCheckMicPermission
}: ControlPanelProps) {
  
  // –ï—Å–ª–∏ –∑–∞–ø–∏—Å—å –∏–¥–µ—Ç, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —ç–∫—Ä–∞–Ω –∑–∞–ø–∏—Å–∏
  if (isRecording) {
    return (
      <div className="recording-screen">
        {/* Top panel - recording controls */}
        <div className="recording-screen__header">
          <div className="control-panel control-panel--recording">
            <div className="control-panel__actions">
              {/* Stop button */}
              <button onClick={onStopRecording} className="stop-button">
                <div className="stop-button__icon"></div>
              </button>
              
              {/* Wave Loader Recording indicator */}
              <WaveLoader 
                isActive={true}
                audioLevel={audioLevel}
                className="wave-loader--recording"
              />
            </div>
            
            <div className="control-panel__separator"></div>
            
            {/* Drag zone */}
            <div className="control-panel__drag-zone" style={{WebkitAppRegion: 'drag'}}>
              <div className="drag-dots">
                <div className="drag-dots__dot"></div>
                <div className="drag-dots__dot"></div>
                <div className="drag-dots__dot"></div>
                <div className="drag-dots__dot"></div>
              </div>
            </div>
          </div>
        </div>

        {/* Main content area */}
        <div className="recording-screen__content">
          {/* Transcript section */}
          <div className="transcript-section">
            <div className="transcript-section__header">
              <h3>Transcript</h3>
            </div>
            <div className="transcript-section__content">
              {transcript ? (
                <div className="transcript-text">
                  {transcript}
                  {partialTranscript && (
                    <span className="transcript-text--partial">
                      {partialTranscript}
                    </span>
                  )}
                </div>
              ) : (
                <div className="transcript-placeholder">
                  {partialTranscript || 'Start speaking to see transcript...'}
                </div>
              )}
            </div>
          </div>

          {/* Insights section */}
          {insights.length > 0 && (
            <div className="insights-section">
              <div className="insights-section__header">
                <h3>Insights</h3>
              </div>
              <div className="insights-section__content">
                {insights.map((insight) => (
                  <div 
                    key={insight.id} 
                    className={`insight insight--${insight.type}`}
                  >
                    {insight.text}
                  </div>
                ))}
              </div>
            </div>
          )}
        </div>
      </div>
    );
  }

  // –ï—Å–ª–∏ –Ω–µ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ä—Ç–æ–≤—ã–π —ç–∫—Ä–∞–Ω
  return (
    <div className="w-full h-full flex items-center justify-center">
      <div className="control-panel">
        <div className="control-panel__actions">
          <button
            onClick={() => {
              if (hasPermission) {
                onStartRecording();
              } else {
                onCheckMicPermission();
              }
            }}
            className="start-button"
            style={{WebkitAppRegion: 'no-drag'}}
          >
            <div className="start-button__icon">
              <div className="start-button__icon-rect"></div>
              <svg className="start-button__icon-svg" viewBox="0 0 8 10" fill="none">
                <ellipse cx="4" cy="8" rx="4" ry="2" stroke="white" strokeWidth="1.4"/>
              </svg>
            </div>
            <span>{hasPermission ? 'Start' : 'Allow Mic'}</span>
          </button>
        </div>
        
        <div className="control-panel__separator"></div>
        
        <div className="control-panel__drag-zone" style={{WebkitAppRegion: 'drag'}}>
          <div className="drag-dots">
            <div className="drag-dots__dot"></div>
            <div className="drag-dots__dot"></div>
            <div className="drag-dots__dot"></div>
            <div className="drag-dots__dot"></div>
          </div>
        </div>
      </div>
    </div>
  );
}
```

### **2. Data Window Component**

**–§–∞–π–ª:** `src/components/DataWindow.tsx`

```typescript
export function DataWindow({
  transcript,
  partialTranscript,
  insights,
  isRecording
}: DataWindowProps) {
  return (
    <div className="data-window">
      {/* Header */}
      <div className="data-window__header">
        <h2>Interview Assistant</h2>
        <div className={`recording-indicator ${isRecording ? 'recording-indicator--active' : ''}`}>
          {isRecording ? '‚óè Recording' : '‚óã Stopped'}
        </div>
      </div>

      {/* Transcript section */}
      <div className="data-window__transcript">
        <h3>Transcript</h3>
        <div className="transcript-content">
          {transcript ? (
            <div className="transcript-text">
              {transcript}
              {partialTranscript && (
                <span className="transcript-text--partial">
                  {partialTranscript}
                </span>
              )}
            </div>
          ) : (
            <div className="transcript-placeholder">
              {partialTranscript || 'No transcript yet...'}
            </div>
          )}
        </div>
      </div>

      {/* Insights section */}
      {insights.length > 0 && (
        <div className="data-window__insights">
          <h3>Insights</h3>
          <div className="insights-content">
            {insights.map((insight) => (
              <div 
                key={insight.id} 
                className={`insight insight--${insight.type}`}
              >
                {insight.text}
              </div>
            ))}
          </div>
        </div>
      )}
    </div>
  );
}
```

### **3. Wave Loader Component**

**–§–∞–π–ª:** `src/components/WaveLoader.tsx`

```typescript
export function WaveLoader({ 
  isActive, 
  audioLevel, 
  className 
}: WaveLoaderProps) {
  const [animationPhase, setAnimationPhase] = useState(0);
  
  useEffect(() => {
    if (!isActive) return;
    
    const interval = setInterval(() => {
      setAnimationPhase(prev => (prev + 1) % 4);
    }, 150);
    
    return () => clearInterval(interval);
  }, [isActive]);
  
  return (
    <div className={`wave-loader ${className || ''}`}>
      <div className="wave-loader__bars">
        {[0, 1, 2, 3].map((index) => (
          <div
            key={index}
            className={`wave-loader__bar ${
              isActive && animationPhase === index ? 'wave-loader__bar--active' : ''
            }`}
            style={{
              height: isActive ? `${Math.max(4, audioLevel * 20)}px` : '4px'
            }}
          />
        ))}
      </div>
    </div>
  );
}
```

---

## üîÑ **–ü–†–û–¶–ï–°–° –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–ò –°–û–°–¢–û–Ø–ù–ò–Ø**

### **1. Audio Recording Hook**

**–§–∞–π–ª:** `src/hooks/useAudioRecording.ts`

```typescript
export const useAudioRecording = (): UseAudioRecordingReturn => {
  const [hasPermission, setHasPermission] = useState<boolean>(false);

  const checkMicPermission = useCallback(async () => {
    try {
      console.log('üé§ Checking microphone permission...');
      const audioConstraints = configService.getAudioConstraints();
      const stream = await navigator.mediaDevices.getUserMedia(audioConstraints);
      console.log('‚úÖ Microphone permission granted!');
      setHasPermission(true);
      stream.getTracks().forEach(track => track.stop());
    } catch (error) {
      console.error('‚ùå Microphone permission denied:', error);
      setHasPermission(false);
    }
  }, []);

  return {
    hasPermission,
    setHasPermission,
    checkMicPermission
  };
};
```

### **2. Audio Analyser Hook**

**–§–∞–π–ª:** `src/hooks/useAudioAnalyser.ts`

```typescript
export const useAudioAnalyser = () => {
  const [audioLevel, setAudioLevel] = useState<number>(0);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);

  const initAudioAnalyser = useCallback((stream: MediaStream) => {
    const audioContext = new AudioContext();
    const source = audioContext.createMediaStreamSource(stream);
    const analyser = audioContext.createAnalyser();
    
    analyser.fftSize = 256;
    analyser.smoothingTimeConstant = 0.8;
    
    source.connect(analyser);
    analyserRef.current = analyser;
    
    // –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞
    const analyzeAudio = () => {
      if (!analyserRef.current) return;
      
      const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);
      analyserRef.current.getByteFrequencyData(dataArray);
      
      // –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å
      const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
      setAudioLevel(average / 255); // –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 0-1
      
      animationFrameRef.current = requestAnimationFrame(analyzeAudio);
    };
    
    analyzeAudio();
  }, []);

  const stopAudioAnalyser = useCallback(() => {
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
    analyserRef.current = null;
    setAudioLevel(0);
  }, []);

  return {
    audioLevel,
    initAudioAnalyser,
    stopAudioAnalyser
  };
};
```

---

## üõ°Ô∏è **–ü–†–û–¶–ï–°–° –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò**

### **1. Electron Security Settings**

**–§–∞–π–ª:** `src/main/main.ts`

```typescript
webPreferences: {
  nodeIntegration: false,       // ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û - –æ—Ç–∫–ª—é—á–µ–Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Node.js
  contextIsolation: true,       // ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û - –∏–∑–æ–ª—è—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
  webSecurity: true,            // ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û - –≤–µ–±-–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –≤–∫–ª—é—á–µ–Ω–∞
  backgroundThrottling: false,  // –û—Ç–∫–ª—é—á–∞–µ–º throttling –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
  enableRemoteModule: false,    // –û—Ç–∫–ª—é—á–∞–µ–º remote module
  preload: path.join(__dirname, '..', 'preload', 'preload.js') // Preload script
}
```

### **2. Preload Script Security**

**–§–∞–π–ª:** `src/preload/preload.ts`

```typescript
import { contextBridge, ipcRenderer } from 'electron';

// –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π API –¥–ª—è renderer –ø—Ä–æ—Ü–µ—Å—Å–∞
contextBridge.exposeInMainWorld('electronAPI', {
  // –¢–æ–ª—å–∫–æ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –º–µ—Ç–æ–¥—ã
  getConfig: () => Promise.resolve({ 
    audio: { sampleRate: 16000 }, 
    ui: { theme: 'dark' },
    env: {
      DEEPGRAM_API_KEY: process.env.DEEPGRAM_API_KEY || '',
      CLAUDE_API_KEY: process.env.CLAUDE_API_KEY || '',
      OPENAI_API_KEY: process.env.OPENAI_API_KEY || '',
      POST_EDITOR_API_KEY: process.env.POST_EDITOR_API_KEY || '',
      NODE_ENV: process.env.NODE_ENV || 'development'
    }
  }),
  
  // IPC –º–µ—Ç–æ–¥—ã
  sendTranscript: (data: any) => ipcRenderer.invoke('send-transcript', data),
  sendInsights: (data: any) => ipcRenderer.invoke('send-insights', data),
  sendRecordingState: (data: any) => ipcRenderer.invoke('send-recording-state', data),
  createDataWindow: () => ipcRenderer.invoke('create-data-window'),
  closeDataWindow: () => ipcRenderer.invoke('close-data-window'),
  
  // –°–ª—É—à–∞—Ç–µ–ª–∏ —Å–æ–±—ã—Ç–∏–π
  onTranscriptUpdate: (callback: (data: any) => void) => {
    const handler = (event: any, data: any) => callback(data);
    ipcRenderer.on('transcript-update', handler);
    return () => ipcRenderer.removeListener('transcript-update', handler);
  },
  
  onInsightsUpdate: (callback: (data: any) => void) => {
    const handler = (event: any, data: any) => callback(data);
    ipcRenderer.on('insights-update', handler);
    return () => ipcRenderer.removeListener('insights-update', handler);
  },
  
  onRecordingStateChange: (callback: (data: any) => void) => {
    const handler = (event: any, data: any) => callback(data);
    ipcRenderer.on('recording-state-change', handler);
    return () => ipcRenderer.removeListener('recording-state-change', handler);
  },
  
  onWindowCreated: (callback: (windowId: string) => void) => {
    const handler = (event: any, windowId: string) => callback(windowId);
    ipcRenderer.on('window-created', handler);
    return () => ipcRenderer.removeListener('window-created', handler);
  },
  
  onWindowClosed: (callback: (windowId: string) => void) => {
    const handler = (event: any, windowId: string) => callback(windowId);
    ipcRenderer.on('window-closed', handler);
    return () => ipcRenderer.removeListener('window-closed', handler);
  },
  
  removeAllListeners: (channel: string) => {
    ipcRenderer.removeAllListeners(channel);
  }
  
  // –ù–ï —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º API –∫–ª—é—á–∏ –Ω–∞–ø—Ä—è–º—É—é!
});
```

### **3. Environment Variables Security**

**–ü—Ä–æ–±–ª–µ–º–∞:** API –∫–ª—é—á–∏ –ø–æ–ø–∞–¥–∞—é—Ç –≤ bundle —á–µ—Ä–µ–∑ `vite.config.js`

```javascript
// ‚ùå –ù–ï–ë–ï–ó–û–ü–ê–°–ù–û –≤ vite.config.js
define: {
  'process.env.DEEPGRAM_API_KEY': JSON.stringify(process.env.DEEPGRAM_API_KEY || ''),
  'process.env.CLAUDE_API_KEY': JSON.stringify(process.env.CLAUDE_API_KEY || ''),
}
```

**–†–µ—à–µ–Ω–∏–µ:** –ü–µ—Ä–µ–¥–∞—á–∞ —á–µ—Ä–µ–∑ preload script

```typescript
// ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û –≤ preload.ts
contextBridge.exposeInMainWorld('electronAPI', {
  getConfig: () => Promise.resolve({
    env: {
      DEEPGRAM_API_KEY: process.env.DEEPGRAM_API_KEY || '',
      CLAUDE_API_KEY: process.env.CLAUDE_API_KEY || '',
    }
  })
});
```

---

## üì¶ **–ü–†–û–¶–ï–°–° –°–ë–û–†–ö–ò –ò –†–ê–ó–í–ï–†–¢–´–í–ê–ù–ò–Ø**

### **1. Package.json Scripts**

**–§–∞–π–ª:** `package.json`

```json
{
  "scripts": {
    "dev": "concurrently \"npm run dev:vite\" \"wait-on http://localhost:5173 && npm run dev:electron\"",
    "dev:vite": "vite",
    "dev:electron": "tsc -p tsconfig.main.json && electron dist/main/main/main.js",
    "build": "npm run build:vite && npm run build:electron",
    "build:vite": "vite build",
    "build:electron": "tsc -p tsconfig.main.json",
    "compile-main": "tsc -p tsconfig.main.json",
    "clean": "rimraf dist",
    "type-check": "tsc --noEmit"
  }
}
```

### **2. TypeScript Configuration**

**–§–∞–π–ª:** `tsconfig.main.json`

```json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "target": "ES2020",
    "module": "CommonJS",
    "outDir": "dist/main",
    "rootDir": "src/main",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true
  },
  "include": [
    "src/main/**/*",
    "src/preload/**/*"
  ],
  "exclude": [
    "node_modules",
    "dist",
    "src/renderer"
  ]
}
```

### **3. Vite Build Configuration**

**–§–∞–π–ª:** `vite.config.js`

```javascript
export default defineConfig({
  plugins: [react()],
  base: './',
  
  server: {
    port: 5173,
    strictPort: true,
    host: 'localhost'
  },
  
  resolve: {
    alias: {
      '@': resolve(__dirname, 'src'),
      '@/types': resolve(__dirname, 'src/types'),
      '@/components': resolve(__dirname, 'src/components'),
      '@/hooks': resolve(__dirname, 'src/hooks'),
      '@/services': resolve(__dirname, 'src/services')
    }
  },
  
  build: {
    outDir: 'dist/renderer',
    emptyOutDir: true,
    target: 'esnext',
    minify: process.env.NODE_ENV === 'production',
    sourcemap: process.env.NODE_ENV === 'development'
  },
  
  optimizeDeps: {
    include: ['react', 'react-dom', 'zod']
  }
});
```

---

## üîß **–ü–†–û–¶–ï–°–° –û–¢–õ–ê–î–ö–ò –ò –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê**

### **1. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ Development**

```typescript
// –í–∫–ª—é—á–µ–Ω–∏–µ DevTools –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
if (configService.isDevelopment) {
  console.log('üîß Development mode - logging config...');
  configService.logConfig();
}

// DevTools –¥–ª—è –ø–∞–Ω–µ–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
controlPanelWindow.webContents.once('did-finish-load', () => {
  console.log('üîß Opening DevTools for control panel');
  controlPanelWindow?.webContents.openDevTools({ mode: 'detach' });
});

// DevTools –¥–ª—è –æ–∫–Ω–∞ –¥–∞–Ω–Ω—ã—Ö
dataWindow.webContents.on('did-finish-load', () => {
  console.log('üîß Opening DevTools for data window');
  dataWindow.webContents.openDevTools();
});
```

### **2. –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –≥–æ—Ä—è—á–∏–µ –∫–ª–∞–≤–∏—à–∏**

```typescript
function registerGlobalShortcuts() {
  // Ctrl/Cmd + \ –¥–ª—è –ø–æ–∫–∞–∑–∞/—Å–∫—Ä—ã—Ç–∏—è –ø–∞–Ω–µ–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
  globalShortcut.register('CommandOrControl+\\', () => {
    if (controlPanelWindow) {
      if (controlPanelWindow.isVisible()) {
        controlPanelWindow.hide();
        if (dataWindow) dataWindow.hide();
      } else {
        controlPanelWindow.show();
        controlPanelWindow.focus();
        if (dataWindow) dataWindow.show();
      }
    }
  });

  console.log('Global shortcuts registered');
}
```

### **3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫**

```typescript
// –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∏—Å–∫–ª—é—á–µ–Ω–∏–π
process.on('uncaughtException', (error) => {
  console.error('Uncaught Exception:', error);
});

process.on('unhandledRejection', (reason, promise) => {
  console.error('Unhandled Rejection at:', promise, 'reason:', reason);
});

// –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ WebSocket
this.ws.onerror = (error) => {
  console.error('‚ùå [DEEPGRAM] WebSocket error:', error);
  this.onError('WebSocket connection error');
};

// –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ Claude API
catch (error) {
  console.error('‚ùå Claude analysis error:', error);
  
  // Fallback insight –Ω–∞ –æ—à–∏–±–∫—É
  return {
    topic: 'Analysis Error',
    depth_score: 0,
    signals: ['API error occurred'],
    followups: [],
    note: 'AI analysis temporarily unavailable',
    type: 'risk',
    confidence: 0
  };
}
```

---

## üìã **–ü–û–õ–ù–´–ô –ñ–ò–ó–ù–ï–ù–ù–´–ô –¶–ò–ö–õ –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø**

### **1. –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è**

```
1. npm run dev
   ‚îú‚îÄ‚îÄ npm run dev:vite (–∑–∞–ø—É—Å–∫ Vite —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ :5173)
   ‚îî‚îÄ‚îÄ wait-on http://localhost:5173 && npm run dev:electron
       ‚îú‚îÄ‚îÄ tsc -p tsconfig.main.json (–∫–æ–º–ø–∏–ª—è—Ü–∏—è main –ø—Ä–æ—Ü–µ—Å—Å–∞)
       ‚îî‚îÄ‚îÄ electron dist/main/main/main.js (–∑–∞–ø—É—Å–∫ Electron)

2. app.whenReady()
   ‚îú‚îÄ‚îÄ createControlPanelWindow() (—Å–æ–∑–¥–∞–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–≥–æ –æ–∫–Ω–∞)
   ‚îú‚îÄ‚îÄ registerGlobalShortcuts() (—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è Ctrl+\)
   ‚îî‚îÄ‚îÄ setupIPC() (–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ IPC –∫–∞–Ω–∞–ª–æ–≤)

3. React App –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è
   ‚îú‚îÄ‚îÄ App.tsx –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç windowType –∏–∑ URL
   ‚îú‚îÄ‚îÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è —Ö—É–∫–∏ (useTranscription, useAudioRecording)
   ‚îî‚îÄ‚îÄ –†–µ–Ω–¥–µ—Ä–∏—Ç—Å—è ControlPanel –∏–ª–∏ DataWindow
```

### **2. –ù–∞—á–∞–ª–æ –∑–∞–ø–∏—Å–∏**

```
1. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∂–∏–º–∞–µ—Ç "Start"
   ‚îú‚îÄ‚îÄ onStartRecording() –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è
   ‚îú‚îÄ‚îÄ setIsRecording(true) - –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ UI
   ‚îî‚îÄ‚îÄ setTimeout(() => { ... }, 100) - –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏

2. –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
   ‚îú‚îÄ‚îÄ navigator.mediaDevices.getUserMedia(audioConstraints)
   ‚îú‚îÄ‚îÄ streamRef.current = stream
   ‚îî‚îÄ‚îÄ initAudioAnalyser(stream) - –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞

3. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Deepgram
   ‚îú‚îÄ‚îÄ configService.getConfigWithEnv() - –∑–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
   ‚îú‚îÄ‚îÄ TranscriptionServiceFactory.create() - —Å–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞
   ‚îú‚îÄ‚îÄ deepgram.connect() - WebSocket –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
   ‚îî‚îÄ‚îÄ cleanupRef.current = cleanup - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—á–∏—Å—Ç–∫–∏

4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞—É–¥–∏–æ pipeline
   ‚îú‚îÄ‚îÄ new AudioContext({ sampleRate: 16000 })
   ‚îú‚îÄ‚îÄ audioContext.audioWorklet.addModule('/audioWorklet.js')
   ‚îú‚îÄ‚îÄ new AudioWorkletNode(audioContext, 'pcm-processor')
   ‚îî‚îÄ‚îÄ workletNode.port.onmessage - –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö
```

### **3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏**

```
1. –ê—É–¥–∏–æ –ø–æ—Ç–æ–∫
   ‚îú‚îÄ‚îÄ MediaStream ‚Üí AudioContext ‚Üí AudioWorkletNode
   ‚îú‚îÄ‚îÄ PCMProcessor.process() - –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è Float32 ‚Üí Int16
   ‚îî‚îÄ‚îÄ workletNode.port.postMessage() - –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ main thread

2. Deepgram WebSocket
   ‚îú‚îÄ‚îÄ ws.send(pcm16.buffer) - –æ—Ç–ø—Ä–∞–≤–∫–∞ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö
   ‚îú‚îÄ‚îÄ ws.onmessage - –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
   ‚îú‚îÄ‚îÄ JSON.parse(event.data) - –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞
   ‚îî‚îÄ‚îÄ adaptiveASR.analyzeTranscript() - –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑

3. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
   ‚îú‚îÄ‚îÄ –°–æ–∑–¥–∞–Ω–∏–µ TranscriptEvent (partial/final)
   ‚îú‚îÄ‚îÄ getTranscriptLogger().logTranscript() - –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
   ‚îú‚îÄ‚îÄ this.onTranscript(transcriptEvent) - –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ UI
   ‚îî‚îÄ‚îÄ postEditor.correctText() - –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

4. –ê–Ω–∞–ª–∏–∑ —Å Claude AI
   ‚îú‚îÄ‚îÄ analysisContextRef.current.addTranscript(newText)
   ‚îú‚îÄ‚îÄ claudeRef.current.analyzeTranscript(analysisRequest)
   ‚îú‚îÄ‚îÄ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ LegacyInsight
   ‚îî‚îÄ‚îÄ setInsights(prev => [...prev.slice(-2), legacyInsight])
```

### **4. –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –º–µ–∂–¥—É –æ–∫–Ω–∞–º–∏**

```
1. Control Panel ‚Üí Data Window
   ‚îú‚îÄ‚îÄ useDataSync.sendToDataWindow('transcript', data)
   ‚îú‚îÄ‚îÄ window.electronAPI.sendTranscript(data)
   ‚îú‚îÄ‚îÄ ipcRenderer.invoke('send-transcript', data)
   ‚îî‚îÄ‚îÄ ipcMain.handle('send-transcript') ‚Üí dataWindow.webContents.send()

2. Data Window –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
   ‚îú‚îÄ‚îÄ window.electronAPI.onTranscriptUpdate(callback)
   ‚îú‚îÄ‚îÄ ipcRenderer.on('transcript-update', handler)
   ‚îî‚îÄ‚îÄ onTranscriptUpdate(data) - –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è

3. –û—á–µ—Ä–µ–¥—å –¥–∞–Ω–Ω—ã—Ö
   ‚îú‚îÄ‚îÄ pendingTranscriptData.push(data) - –µ—Å–ª–∏ –æ–∫–Ω–æ –Ω–µ —Å–æ–∑–¥–∞–Ω–æ
   ‚îú‚îÄ‚îÄ processPendingData() - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –æ–∫–Ω–∞
   ‚îî‚îÄ‚îÄ dataWindow.webContents.send() - –æ—Ç–ø—Ä–∞–≤–∫–∞ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
```

### **5. –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏**

```
1. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∂–∏–º–∞–µ—Ç "Stop"
   ‚îú‚îÄ‚îÄ onStopRecording() –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è
   ‚îî‚îÄ‚îÄ –û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö —Ä–µ—Å—É—Ä—Å–æ–≤

2. –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞—É–¥–∏–æ pipeline
   ‚îú‚îÄ‚îÄ processorRef.current.disconnect()
   ‚îú‚îÄ‚îÄ audioContextRef.current.close()
   ‚îî‚îÄ‚îÄ streamRef.current.getTracks().forEach(track => track.stop())

3. –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç Deepgram
   ‚îú‚îÄ‚îÄ cleanupRef.current() - –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—á–∏—Å—Ç–∫–∏
   ‚îú‚îÄ‚îÄ deepgram.disconnect()
   ‚îú‚îÄ