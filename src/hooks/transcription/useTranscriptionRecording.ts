import { useCallback } from 'react';
import { configService } from '../../services/config';
import { useAudioAnalyser } from '../useAudioAnalyser';

/**
 * Recording functionality for transcription hook
 * 
 * @example
 * ```tsx
 * const recording = useTranscriptionRecording({
 *   streamRef,
 *   audioContextRef,
 *   processorRef,
 *   cleanupRef,
 *   deepgramRef,
 *   setIsRecording,
 *   initAudioAnalyser,
 *   stopAudioAnalyser,
 *   connectToDeepgram
 * });
 * ```
 */
interface UseTranscriptionRecordingProps {
  streamRef: React.MutableRefObject<MediaStream | null>;
  audioContextRef: React.MutableRefObject<AudioContext | null>;
  processorRef: React.MutableRefObject<ScriptProcessorNode | AudioWorkletNode | null>;
  cleanupRef: React.MutableRefObject<(() => void) | null>;
  deepgramRef: React.MutableRefObject<any>;
  setIsRecording: (recording: boolean) => void;
  initAudioAnalyser: (stream: MediaStream) => void;
  stopAudioAnalyser: () => void;
  connectToDeepgram: () => Promise<() => void>;
}

export const useTranscriptionRecording = ({
  streamRef,
  audioContextRef,
  processorRef,
  cleanupRef,
  deepgramRef,
  setIsRecording,
  initAudioAnalyser,
  stopAudioAnalyser,
  connectToDeepgram
}: UseTranscriptionRecordingProps) => {

  /**
   * Start recording
   */
  const startRecording = useCallback(async (): Promise<void> => {
    console.log('üé¨ [useTranscription] Starting recording...');
    
    try {
      // –û–±–Ω–æ–≤–ª—è–µ–º UI —Å–æ—Å—Ç–æ—è–Ω–∏–µ
      setIsRecording(true);
      
      // –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
      const audioConstraints = configService.getAudioConstraints();
      console.log('üé§ [useTranscription] Requesting microphone access...');
      
      const stream = await navigator.mediaDevices.getUserMedia(audioConstraints);
      streamRef.current = stream;
      
      console.log('‚úÖ [useTranscription] Microphone access granted');
      
      // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∞—É–¥–∏–æ
      initAudioAnalyser(stream);
      
      // –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Deepgram
      const cleanup = await connectToDeepgram();
      cleanupRef.current = cleanup;
      
      // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∞—É–¥–∏–æ pipeline
      const audioContext = new AudioContext({ sampleRate: 16000 });
      audioContextRef.current = audioContext;
      
      console.log('üîä [useTranscription] Setting up audio pipeline...');
      
      try {
        // –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å AudioWorklet (—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥)
        await audioContext.audioWorklet.addModule('/audioWorklet.js');
        
        const source = audioContext.createMediaStreamSource(stream);
        const workletNode = new AudioWorkletNode(audioContext, 'pcm-processor');
        
        // –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö
        workletNode.port.onmessage = (event) => {
          if (event.data.type === 'pcm-data' && deepgramRef.current) {
            deepgramRef.current.sendAudio(event.data.data);
          }
        };
        
        source.connect(workletNode);
        processorRef.current = workletNode;
        
        console.log('‚úÖ [useTranscription] AudioWorklet pipeline ready');
        
      } catch (workletError) {
        console.warn('‚ö†Ô∏è [useTranscription] AudioWorklet failed, falling back to ScriptProcessor:', workletError);
        
        // Fallback –Ω–∞ ScriptProcessor
        const source = audioContext.createMediaStreamSource(stream);
        const processor = audioContext.createScriptProcessor(4096, 1, 1);
        
        processor.onaudioprocess = (event) => {
          const inputData = event.inputBuffer.getChannelData(0);
          
          // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Float32 –≤ Int16
          const pcm16 = new Int16Array(inputData.length);
          for (let i = 0; i < inputData.length; i++) {
            pcm16[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
          }
          
          // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ Deepgram
          if (deepgramRef.current) {
            deepgramRef.current.sendAudio(pcm16.buffer);
          }
        };
        
        source.connect(processor);
        processor.connect(audioContext.destination);
        processorRef.current = processor;
        
        console.log('‚úÖ [useTranscription] ScriptProcessor pipeline ready');
      }
      
      console.log('üéâ [useTranscription] Recording started successfully!');
      
    } catch (error) {
      console.error('‚ùå [useTranscription] Failed to start recording:', error);
      setIsRecording(false);
      throw error;
    }
  }, [
    setIsRecording,
    streamRef,
    audioContextRef,
    processorRef,
    cleanupRef,
    deepgramRef,
    initAudioAnalyser,
    connectToDeepgram
  ]);

  /**
   * Stop recording
   */
  const stopRecording = useCallback((): void => {
    console.log('‚èπÔ∏è [useTranscription] Stopping recording...');
    
    try {
      // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞—É–¥–∏–æ pipeline
      if (processorRef.current) {
        processorRef.current.disconnect();
        processorRef.current = null;
      }
      
      // –ó–∞–∫—Ä—ã–≤–∞–µ–º –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç
      if (audioContextRef.current) {
        audioContextRef.current.close();
        audioContextRef.current = null;
      }
      
      // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ç–æ–∫
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }
      
      // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
      stopAudioAnalyser();
      
      // –û—Ç–∫–ª—é—á–∞–µ–º—Å—è –æ—Ç Deepgram
      if (cleanupRef.current) {
        cleanupRef.current();
        cleanupRef.current = null;
      }
      
      // –û–±–Ω–æ–≤–ª—è–µ–º UI —Å–æ—Å—Ç–æ—è–Ω–∏–µ
      setIsRecording(false);
      
      console.log('‚úÖ [useTranscription] Recording stopped successfully!');
      
    } catch (error) {
      console.error('‚ùå [useTranscription] Error stopping recording:', error);
      setIsRecording(false);
    }
  }, [
    processorRef,
    audioContextRef,
    streamRef,
    stopAudioAnalyser,
    cleanupRef,
    setIsRecording
  ]);

  return {
    startRecording,
    stopRecording
  };
};
