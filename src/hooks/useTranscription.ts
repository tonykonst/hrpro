import { useState, useRef, useCallback } from 'react';
import { TranscriptEvent } from '../services/deepgram';
import { ITranscriptionService } from '../types/ITranscriptionService';
import { TranscriptionServiceFactory } from '../services/transcription/TranscriptionServiceFactory';
import { createClaudeService, ClaudeAnalysisService, AnalysisContext, InsightResponse } from '../services/claude';
import { configService } from '../services/config';
import { LegacyInsight } from '../types/events';
import { PostEditorConfig, CorrectionContext } from '../services/post-editor';
import { useAudioAnalyser } from './useAudioAnalyser';

export interface UseTranscriptionReturn {
  // –°–æ—Å—Ç–æ—è–Ω–∏—è
  transcript: string;
  partialTranscript: string;
  insights: LegacyInsight[];
  isRecording: boolean;
  audioLevel: number;
  
  // –ú–µ—Ç–æ–¥—ã
  setTranscript: (transcript: string) => void;
  setPartialTranscript: (partialTranscript: string) => void;
  setInsights: (insights: LegacyInsight[]) => void;
  setIsRecording: (isRecording: boolean) => void;
  
  // –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
  startRecording: () => Promise<void>;
  stopRecording: () => void;
  connectToDeepgram: () => Promise<() => void>;
  analyzeWithClaude: (newText: string) => Promise<void>;
}

export const useTranscription = (): UseTranscriptionReturn => {
  // –°–æ—Å—Ç–æ—è–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
  const [transcript, setTranscript] = useState<string>('');
  const [partialTranscript, setPartialTranscript] = useState<string>('');
  const [insights, setInsights] = useState<LegacyInsight[]>([]);
  const [isRecording, setIsRecording] = useState<boolean>(false);
  
  // Refs –¥–ª—è —Å–µ—Ä–≤–∏—Å–æ–≤
  const streamRef = useRef<MediaStream | null>(null);
  const deepgramRef = useRef<ITranscriptionService | null>(null);
  const claudeRef = useRef<ClaudeAnalysisService | null>(null);
  const analysisContextRef = useRef<AnalysisContext | null>(null);
  const cleanupRef = useRef<(() => void) | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const processorRef = useRef<ScriptProcessorNode | AudioWorkletNode | null>(null);
  
  // Audio analyser hook
  const { audioLevel, initAudioAnalyser, stopAudioAnalyser } = useAudioAnalyser();

  // –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Deepgram
  const connectToDeepgram = useCallback(async (): Promise<() => void> => {
    console.log('üîó [useTranscription] [DEEPGRAM] Starting Deepgram connection...');
    
    // –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ electronAPI
    await configService.getConfigWithEnv();
    
    // –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ dev —Ä–µ–∂–∏–º–µ
    if (configService.isDevelopment) {
      console.log('üîß [DEEPGRAM] Development mode - logging config...');
      configService.logConfig();
    }
    
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Deepgram
    if (!configService.isDeepgramConfigured()) {
      throw new Error('‚ùå [DEEPGRAM] API key not configured! Please add DEEPGRAM_API_KEY to .env file');
    }
    
    console.log('‚úÖ [DEEPGRAM] API key configured, proceeding with real connection...');

    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Claude —Å–µ—Ä–≤–∏—Å –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
    if (configService.isClaudeConfigured()) {
      try {
        const claudeConfig = configService.getClaudeConfig();
        claudeRef.current = createClaudeService(claudeConfig);
        analysisContextRef.current = new AnalysisContext();
        console.log('‚úÖ Claude service initialized:', {
          model: claudeConfig.model,
          maxTokens: claudeConfig.maxTokens,
          temperature: claudeConfig.temperature
        });
      } catch (error) {
        console.warn('‚ö†Ô∏è Claude service failed to initialize:', error);
      }
    } else {
      console.log('‚ö†Ô∏è Claude API key not configured, insights will be limited...');
    }

    try {
      console.log('üì° [DEEPGRAM] Connecting to real Deepgram...');
      
      const deepgramConfig = configService.getDeepgramConfig();
      console.log('üîß [DEEPGRAM] Using config:', {
        model: deepgramConfig.model,
        language: deepgramConfig.language,
        interim_results: deepgramConfig.interim_results,
        endpointing: deepgramConfig.endpointing
      });
      
      // –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ—Å—Ç—Ä–µ–¥–∞–∫—Ç–æ—Ä–∞
      let postEditorConfig: PostEditorConfig | undefined;
      let correctionContext: CorrectionContext | undefined;
      
      if (configService.isPostEditorConfigured()) {
        postEditorConfig = configService.getPostEditorConfig();
        correctionContext = {
          jobTerms: [],
          synonymDictionary: {}
        };
        console.log('üîß Post-editor enabled:', {
          model: postEditorConfig.model,
          timeout: postEditorConfig.timeoutMs
        });
      } else {
        console.log('‚ö†Ô∏è Post-editor not configured, skipping...');
      }
      
      // –°–æ–∑–¥–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–æ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å —á–µ—Ä–µ–∑ —Ñ–∞–±—Ä–∏–∫—É
      const deepgram = TranscriptionServiceFactory.create({
        provider: 'deepgram',
        apiKey: deepgramConfig.apiKey,
        onTranscript: async (event: TranscriptEvent) => {
          console.log('üìù [TRANSCRIPT] Received Deepgram event:', {
            type: event.type,
            text: event.text?.substring(0, 50) + '...',
            confidence: event.confidence,
            timestamp: new Date().toLocaleTimeString()
          });
          
          if (event.type === 'partial') {
            const newPartial = event.text;
            setPartialTranscript(newPartial);
            console.log('üîÑ [PARTIAL] Deepgram partial:', newPartial);
          } else if (event.type === 'final') {
            // –û–±–Ω–æ–≤–ª—è–µ–º –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
            const newTranscript = (transcript + ' ' + event.text).trim();
            setTranscript(newTranscript);
            setPartialTranscript('');
            
            console.log('‚úÖ [FINAL] Deepgram final result:', {
              text: event.text,
              confidence: event.confidence,
              length: event.text.length,
              wordCount: event.text.split(' ').length
            });
            
            // –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å –ø–æ–º–æ—â—å—é Claude –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            if (event.text.length > 10) {
              await analyzeWithClaude(event.text);
            }
          }
        },
        onError: (error: string) => {
          console.error('‚ùå [DEEPGRAM] Error:', error);
          setInsights(prev => [...prev.slice(-2), {
            id: Date.now().toString(),
            text: `Deepgram API error: ${error}`,
            type: 'risk'
          }]);
        },
        deepgramConfig,
        postEditorConfig,
        correctionContext
      });

      deepgramRef.current = deepgram;
      await deepgram.connect();
      
      return () => {
        deepgram.disconnect();
        deepgramRef.current = null;
        claudeRef.current = null;
        analysisContextRef.current = null;
      };
      
    } catch (error) {
      console.error('‚ùå [DEEPGRAM] Failed to connect to Deepgram:', error);
      throw error;
    }
  }, [transcript]);

  // –ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ —Å –ø–æ–º–æ—â—å—é Claude AI
  const analyzeWithClaude = useCallback(async (newText: string): Promise<void> => {
    if (!claudeRef.current || !analysisContextRef.current) {
      console.log('‚ö†Ô∏è Claude not available, skipping analysis...');
      return;
    }

    try {
      // –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
      analysisContextRef.current.addTranscript(newText);
      const context = analysisContextRef.current.getContext();

      // –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
      const analysisRequest = {
        transcript: newText,
        contextWindow: context.contextWindow,
        entities: context.entities,
        topicHistory: context.topicHistory
      };

      console.log('ü§ñ Analyzing with Claude...', {
        text_length: newText.length,
        context_words: context.contextWindow.length,
        entities: context.entities.length
      });

      // –ü–æ–ª—É—á–∞–µ–º –∞–Ω–∞–ª–∏–∑ –æ—Ç Claude
      const analysis: InsightResponse = await claudeRef.current.analyzeTranscript(analysisRequest);

      // –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ø–∏–∫ –≤ –∏—Å—Ç–æ—Ä–∏—é
      analysisContextRef.current.addTopic(analysis.topic);

      // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç legacy insight –¥–ª—è UI
      const legacyInsight: LegacyInsight = {
        id: Date.now().toString(),
        text: analysis.note,
        type: analysis.type
      };

      // –û–±–Ω–æ–≤–ª—è–µ–º UI (–ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 insights)
      setInsights(prev => [...prev.slice(-2), legacyInsight]);

      console.log('‚úÖ Claude analysis complete:', {
        topic: analysis.topic,
        depth_score: analysis.depth_score,
        type: analysis.type,
        note_length: analysis.note.length
      });

    } catch (error) {
      console.error('‚ùå Claude analysis failed:', error);
      setInsights(prev => [...prev.slice(-2), {
        id: Date.now().toString(),
        text: `Claude analysis error: ${error}`,
        type: 'risk'
      }]);
    }
  }, []);

  // –ù–∞—á–∞–ª–æ –∑–∞–ø–∏—Å–∏
  const startRecording = useCallback(async () => {
    try {
      console.log('üé¨ [useTranscription] [STEP 1] Starting recording...');
      
      // –°–ù–ê–ß–ê–õ–ê –º–µ–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ UI –¥–ª—è –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–π —Ä–µ–∞–∫—Ü–∏–∏
      setIsRecording(true);
      console.log('‚úÖ [useTranscription] [STEP 2] UI state updated to recording');
      
      // –û—Å—Ç–∞–ª—å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è–µ–º –≤ —Ñ–æ–Ω–µ
      setTimeout(async () => {
        try {
          console.log('üé§ [STEP 3] Getting microphone access...');
          const audioConstraints = configService.getAudioConstraints();
          const stream = await navigator.mediaDevices.getUserMedia(audioConstraints);
          streamRef.current = stream;
          console.log('‚úÖ [STEP 4] Microphone access granted');

          console.log('üéµ [STEP 4.5] Initializing audio analyser...');
          initAudioAnalyser(stream);
          console.log('‚úÖ [STEP 4.5] Audio analyser initialized');

          console.log('üîó [STEP 5] Connecting to Deepgram...');
          const cleanup = await connectToDeepgram();
          cleanupRef.current = cleanup;
          console.log('‚úÖ [STEP 6] Deepgram connected successfully');

          console.log('üéµ [STEP 7] Setting up audio pipeline...');
          
          // –ü–†–û–°–¢–û–ô –ê–£–î–ò–û PIPELINE —Å AudioWorklet
          try {
            const audioContext = new AudioContext({ sampleRate: 16000 });
            await audioContext.audioWorklet.addModule('/audioWorklet.js');
            
            const source = audioContext.createMediaStreamSource(stream);
            const workletNode = new AudioWorkletNode(audioContext, 'pcm-processor');
            
            // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Å—ã–ª–∫–∏ –¥–ª—è cleanup
            audioContextRef.current = audioContext;
            processorRef.current = workletNode as any;
            
            // –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö –æ—Ç worklet
            workletNode.port.onmessage = (event) => {
              if (deepgramRef.current && event.data && event.data.type === 'pcm-data') {
                deepgramRef.current.sendAudio(event.data.data);
                console.log('üì° [AUDIO] Sent', event.data.data.byteLength, 'bytes to Deepgram (AudioWorklet)');
              }
            };
            
            source.connect(workletNode);
            console.log('‚úÖ [STEP 8] AudioWorklet pipeline connected!');
            
          } catch (error) {
            console.warn('‚ö†Ô∏è AudioWorklet failed, falling back to ScriptProcessor:', error);
            
            // Fallback –∫ ScriptProcessor
            const audioContext = new AudioContext({ sampleRate: 16000 });
            const source = audioContext.createMediaStreamSource(stream);
            const processor = audioContext.createScriptProcessor(4096, 1, 1);
            
            audioContextRef.current = audioContext;
            processorRef.current = processor;
            
            processor.onaudioprocess = (event) => {
              if (deepgramRef.current) {
                const inputData = event.inputBuffer.getChannelData(0);
                const pcm16 = new Int16Array(inputData.length);
                for (let i = 0; i < inputData.length; i++) {
                  pcm16[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
                }
                deepgramRef.current.sendAudio(pcm16.buffer);
                console.log('üì° [AUDIO] Sent', pcm16.length, 'samples to Deepgram (ScriptProcessor)');
              }
            };
            
            source.connect(processor);
            processor.connect(audioContext.destination);
            console.log('‚úÖ [STEP 8] ScriptProcessor pipeline connected!');
          }

          console.log('üéØ [STEP 7] Recording started successfully!');
        } catch (error) {
          console.error('‚ùå [ERROR] Failed to start recording:', error);
          setIsRecording(false);
          setInsights(prev => [...prev.slice(-2), {
            id: Date.now().toString(),
            text: `Recording failed: ${error}`,
            type: 'risk'
          }]);
        }
      }, 100);
      
    } catch (error) {
      console.error('‚ùå [ERROR] Start recording failed:', error);
      setIsRecording(false);
    }
  }, [connectToDeepgram, initAudioAnalyser]);

  // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏
  const stopRecording = useCallback(() => {
    console.log('üõë [STOP] Stopping recording...');
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞—É–¥–∏–æ pipeline
    if (processorRef.current) {
      processorRef.current.disconnect();
      processorRef.current = null;
      console.log('üîå [STOP] Audio processor disconnected');
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
      console.log('üîå [STOP] Audio context closed');
    }
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–µ–¥–∏–∞ –ø–æ—Ç–æ–∫
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
      console.log('üîå [STOP] Media stream stopped');
    }
    
    // –û—Ç–∫–ª—é—á–∞–µ–º Deepgram
    if (cleanupRef.current) {
      cleanupRef.current();
      cleanupRef.current = null;
      console.log('üîå [STOP] Deepgram disconnected');
    }
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞—É–¥–∏–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    stopAudioAnalyser();
    console.log('üîå [STOP] Audio analyser stopped');
    
    setIsRecording(false);
    console.log('‚úÖ [STOP] Recording stopped successfully');
  }, [stopAudioAnalyser]);

  return {
    // –°–æ—Å—Ç–æ—è–Ω–∏—è
    transcript,
    partialTranscript,
    insights,
    isRecording,
    audioLevel,
    
    // –ú–µ—Ç–æ–¥—ã
    setTranscript,
    setPartialTranscript,
    setInsights,
    setIsRecording,
    
    // –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
    startRecording,
    stopRecording,
    connectToDeepgram,
    analyzeWithClaude
  };
};
