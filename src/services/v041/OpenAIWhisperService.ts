/**
 * –ù–ê–°–¢–û–Ø–©–ò–ô OpenAI Whisper API —Å–µ—Ä–≤–∏—Å
 * –ë–ï–ó –°–ò–ú–£–õ–Ø–¶–ò–ô! –¢–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ –≤—ã–∑–æ–≤—ã –∫ OpenAI API
 */
export class OpenAIWhisperService {
  private apiKey: string;
  private baseUrl = 'https://api.openai.com/v1/audio/transcriptions';
  
  constructor(apiKey: string) {
    if (!apiKey) {
      throw new Error('OpenAI API key is required');
    }
    this.apiKey = apiKey;
    console.log('ü§ñ OpenAI Whisper API service initialized (REAL API)');
  }

  /**
   * –†–ï–ê–õ–¨–ù–ê–Ø —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —á–µ—Ä–µ–∑ OpenAI Whisper API
   */
  async transcribe(audioBlob: Blob, options?: {
    language?: string;
    prompt?: string;
    temperature?: number;
    response_format?: 'json' | 'verbose_json';
  }): Promise<{
    text: string;
    confidence: number;
    language: string;
    duration: number;
    segments?: any[];
    words?: any[];
  }> {
    const startTime = Date.now();
    
    try {
      // –°–æ–∑–¥–∞–µ–º FormData –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∞—É–¥–∏–æ
      const formData = new FormData();
      formData.append('file', audioBlob, 'audio.webm');
      formData.append('model', 'whisper-1');
      
      // –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã v0.41
      if (options?.language) {
        formData.append('language', options.language);
      }
      
      // –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω—Ç–µ—Ä–≤—å—é
      const techPrompt = options?.prompt || 
        "This is a technical interview. Terms may include: API, React, TypeScript, Docker, Kubernetes, DevOps, CI/CD, machine learning, microservices, architecture, development.";
      formData.append('prompt', techPrompt);
      
      if (options?.temperature !== undefined) {
        formData.append('temperature', options.temperature.toString());
      }
      
      // –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å timestamps
      formData.append('response_format', options?.response_format || 'verbose_json');
      formData.append('timestamp_granularities[]', 'word');

      // –†–ï–ê–õ–¨–ù–´–ô –≤—ã–∑–æ–≤ –∫ OpenAI API
      console.log('üì° Making REAL call to OpenAI Whisper API...');
      
      const response = await fetch(this.baseUrl, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
        },
        body: formData
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`OpenAI API error ${response.status}: ${errorText}`);
      }

      const result = await response.json();
      const processingTime = Date.now() - startTime;
      
      // –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞ OpenAI
      const text = result.text || '';
      const language = result.language || 'unknown';
      const duration = result.duration || 0;
      
      // –í—ã—á–∏—Å–ª—è–µ–º confidence –Ω–∞ –æ—Å–Ω–æ–≤–µ segments (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)
      let confidence = 0.9; // –ë–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è Whisper
      if (result.segments && result.segments.length > 0) {
        const confidences = result.segments
          .filter((seg: any) => seg.avg_logprob !== undefined)
          .map((seg: any) => Math.exp(seg.avg_logprob));
        
        if (confidences.length > 0) {
          confidence = confidences.reduce((sum: number, conf: number) => sum + conf, 0) / confidences.length;
        }
      }

      const finalResult = {
        text: text.trim(),
        confidence,
        language,
        duration,
        segments: result.segments || [],
        words: result.words || []
      };

      console.log(`‚úÖ REAL Whisper API result: "${text.substring(0, 50)}..." (${(confidence * 100).toFixed(1)}%, ${processingTime}ms)`);
      
      return finalResult;
      
    } catch (error) {
      console.error('‚ùå REAL Whisper API error:', error);
      throw new Error(`Whisper API failed: ${error instanceof Error ? error.message : String(error)}`);
    }
  }

  /**
   * –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤
   */
  async transcribeBatch(audioBlobs: Blob[], options?: {
    language?: string;
    prompt?: string;
    concurrency?: number;
  }): Promise<Array<{
    text: string;
    confidence: number;
    language: string;
    duration: number;
    index: number;
  }>> {
    const concurrency = options?.concurrency || 3; // –ú–∞–∫—Å–∏–º—É–º 3 –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
    const results: any[] = [];
    
    console.log(`üîÑ Processing ${audioBlobs.length} audio files with REAL Whisper API (concurrency: ${concurrency})`);
    
    // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞–∫–µ—Ç–∞–º–∏ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –Ω–∞–≥—Ä—É–∑–∫–∏
    for (let i = 0; i < audioBlobs.length; i += concurrency) {
      const batch = audioBlobs.slice(i, i + concurrency);
      const batchPromises = batch.map(async (blob, batchIndex) => {
        const globalIndex = i + batchIndex;
        try {
          const result = await this.transcribe(blob, options);
          return { ...result, index: globalIndex };
        } catch (error) {
          console.error(`‚ùå Batch item ${globalIndex} failed:`, error);
          return {
            text: `[Error: ${error}]`,
            confidence: 0.0,
            language: 'unknown',
            duration: 0,
            index: globalIndex
          };
        }
      });
      
      const batchResults = await Promise.all(batchPromises);
      results.push(...batchResults);
      
      // –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏ –¥–ª—è API rate limits
      if (i + concurrency < audioBlobs.length) {
        await new Promise(resolve => setTimeout(resolve, 100));
      }
    }
    
    console.log(`‚úÖ REAL Whisper API batch completed: ${results.length} results`);
    return results;
  }

  /**
   * –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API
   */
  async testConnection(): Promise<boolean> {
    try {
      // –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π –∞—É–¥–∏–æ —Ñ–∞–π–ª (1 —Å–µ–∫—É–Ω–¥–∞ —Ç–∏—à–∏–Ω—ã –≤ WAV)
      const silentAudio = this.createSilentWAV(1.0); // 1 —Å–µ–∫—É–Ω–¥–∞
      
      console.log('üîÑ Testing REAL OpenAI Whisper API connection...');
      
      const result = await this.transcribe(silentAudio, {
        language: 'en',
        prompt: 'Test connection',
        temperature: 0.0
      });
      
      console.log('‚úÖ REAL OpenAI Whisper API connection successful');
      return true;
      
    } catch (error) {
      console.error('‚ùå REAL OpenAI Whisper API connection failed:', error);
      return false;
    }
  }

  /**
   * –°–æ–∑–¥–∞–µ—Ç WAV —Ñ–∞–π–ª —Å —Ç–∏—à–∏–Ω–æ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
   */
  private createSilentWAV(durationSeconds: number): Blob {
    const sampleRate = 16000;
    const numChannels = 1;
    const bitsPerSample = 16;
    const numSamples = Math.floor(sampleRate * durationSeconds);
    
    // WAV –∑–∞–≥–æ–ª–æ–≤–æ–∫ (44 –±–∞–π—Ç–∞) + –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
    const buffer = new ArrayBuffer(44 + numSamples * 2);
    const view = new DataView(buffer);
    
    // WAV –∑–∞–≥–æ–ª–æ–≤–æ–∫
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + numSamples * 2, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true); // PCM
    view.setUint16(22, numChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * numChannels * bitsPerSample / 8, true);
    view.setUint16(32, numChannels * bitsPerSample / 8, true);
    view.setUint16(34, bitsPerSample, true);
    writeString(36, 'data');
    view.setUint32(40, numSamples * 2, true);
    
    // –ó–∞–ø–æ–ª–Ω—è–µ–º —Ç–∏—à–∏–Ω–æ–π (–≤—Å–µ –Ω—É–ª–∏)
    // –î–∞–Ω–Ω—ã–µ —É–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –Ω—É–ª—è–º–∏ –≤ ArrayBuffer
    
    return new Blob([buffer], { type: 'audio/wav' });
  }

  /**
   * –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
   */
  getModelInfo() {
    return {
      provider: 'OpenAI',
      model: 'whisper-1',
      type: 'cloud_api',
      cost_per_minute: 0.006, // $0.006 per minute
      max_file_size: '25MB',
      supported_formats: ['mp3', 'mp4', 'mpeg', 'mpga', 'm4a', 'wav', 'webm'],
      languages_supported: 99, // Whisper –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 99 —è–∑—ã–∫–æ–≤
      features: [
        'word_timestamps',
        'language_detection', 
        'context_prompts',
        'temperature_control'
      ]
    };
  }
}
