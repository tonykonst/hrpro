import { OpenAIWhisperService } from './OpenAIWhisperService';
import { SmartBufferManager } from './buffering/SmartBufferManager';
import { EnhancedVAD } from './buffering/EnhancedVAD';
import { configService } from '../config';

/**
 * –ù–ê–°–¢–û–Ø–©–ò–ô —Å–µ—Ä–≤–∏—Å –∑–∞–º–µ–Ω—ã Deepgram –Ω–∞ OpenAI Whisper API
 * –ë–ï–ó –°–ò–ú–£–õ–Ø–¶–ò–ô! –¢–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ API –≤—ã–∑–æ–≤—ã
 */
export class RealWhisperReplacementService {
  private whisperApi: OpenAIWhisperService;
  private bufferManager: SmartBufferManager | null = null;
  private vadService: EnhancedVAD | null = null;
  private audioContext: AudioContext | null = null;
  private stream: MediaStream | null = null;
  
  // –°–æ—Å—Ç–æ—è–Ω–∏–µ
  private isActive = false;
  private isInitialized = false;
  
  // Callbacks (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å DeepgramService)
  private onTranscriptCallback?: (event: TranscriptEvent) => void;
  private onErrorCallback?: (error: string) => void;
  
  // –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ
  private processingInterval: NodeJS.Timeout | null = null;
  private bufferCheckInterval: NodeJS.Timeout | null = null;
  
  // –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
  private transcriptHistory: string[] = [];

  constructor() {
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é OpenAI
    if (!configService.isOpenAIConfigured()) {
      throw new Error('OpenAI API key not configured. Add OPENAI_API_KEY to .env file');
    }

    const openaiConfig = configService.getOpenAIConfig();
    this.whisperApi = new OpenAIWhisperService(openaiConfig.apiKey);
    
    console.log('üéØ RealWhisperReplacementService initialized (REAL OpenAI API)');
  }

  /**
   * –ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫—É - –†–ï–ê–õ–¨–ù–ê–Ø –∑–∞–º–µ–Ω–∞ Deepgram
   */
  async connect(): Promise<() => void> {
    try {
      console.log('üîÑ Connecting to REAL Whisper service...');
      
      // –ü–æ–ª—É—á–∞–µ–º –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: false, // –î–ª—è —á–∏—Å—Ç–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
          autoGainControl: false
        }
      });

      this.stream = stream;

      // –°–æ–∑–¥–∞–µ–º –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
        sampleRate: 16000
      });
      this.audioContext = audioContext;

      // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º VAD
      this.vadService = new EnhancedVAD(audioContext, stream);

      // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º smart buffer manager
      this.bufferManager = new SmartBufferManager({
        baseWindowSize: 15, // –£–º–µ–Ω—å—à–∞–µ–º –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        overlapSize: 3,     // 3 —Å–µ–∫—É–Ω–¥—ã –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
        adaptToSpeechRate: true,
        extendOnActiveSpeech: true,
        silenceThreshold: 0.8,  // –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
        energyThreshold: 0.1,
        preSpeechBuffer: 0.5,
        postSpeechBuffer: 1.0
      }, audioContext);

      // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∞—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫—É
      await this.setupAudioProcessing(stream, audioContext);

      // –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –±—É—Ñ–µ—Ä–æ–≤
      this.startBufferMonitoring();

      this.isActive = true;
      console.log('‚úÖ REAL Whisper service connected and active');

      // –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ—á–∏—Å—Ç–∫–∏ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å Deepgram API)
      return () => this.disconnect();

    } catch (error) {
      console.error('‚ùå Failed to connect REAL Whisper service:', error);
      throw error;
    }
  }

  /**
   * –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞
   */
  private async setupAudioProcessing(stream: MediaStream, audioContext: AudioContext): Promise<void> {
    const source = audioContext.createMediaStreamSource(stream);
    const analyser = audioContext.createAnalyser();
    analyser.fftSize = 2048;
    source.connect(analyser);
    
    // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ –∫–∞–∂–¥—ã–µ 100ms
    const processAudio = () => {
      if (!this.isActive || !this.vadService || !this.bufferManager) return;
      
      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(dataArray);
      
      // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ Float32Array –¥–ª—è VAD
      const audioData = new Float32Array(dataArray.length);
      for (let i = 0; i < dataArray.length; i++) {
        audioData[i] = (dataArray[i] - 128) / 128.0;
      }
      
      // –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å VAD
      const vadResult = this.vadService.analyze(audioData);
      
      // –î–æ–±–∞–≤–ª—è–µ–º –≤ smart buffer
      this.bufferManager.addAudioChunk(audioData, vadResult);
    };
    
    this.processingInterval = setInterval(processAudio, 100);
  }

  /**
   * –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≥–æ—Ç–æ–≤—ã—Ö –±—É—Ñ–µ—Ä–æ–≤ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ –ù–ê–°–¢–û–Ø–©–ò–ô Whisper API
   */
  private startBufferMonitoring(): void {
    const checkBuffers = async () => {
      if (!this.bufferManager || !this.isActive) return;

      const readyBuffers = this.bufferManager.getReadyBuffers();
      const unprocessedBuffers = readyBuffers.filter(buffer => !buffer.transcription);

      for (const buffer of unprocessedBuffers) {
        try {
          await this.processBufferWithRealWhisper(buffer);
        } catch (error) {
          console.error(`‚ùå Failed to process buffer ${buffer.id} with REAL Whisper:`, error);
          
          // –£–≤–µ–¥–æ–º–ª—è–µ–º –æ–± –æ—à–∏–±–∫–µ
          if (this.onErrorCallback) {
            this.onErrorCallback(`Whisper processing error: ${error}`);
          }
        }
      }
    };

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –±—É—Ñ–µ—Ä—ã –∫–∞–∂–¥—ã–µ 2 —Å–µ–∫—É–Ω–¥—ã
    this.bufferCheckInterval = setInterval(checkBuffers, 2000);
  }

  /**
   * –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±—É—Ñ–µ—Ä —Å –ù–ê–°–¢–û–Ø–©–ò–ú OpenAI Whisper API
   */
  private async processBufferWithRealWhisper(buffer: any): Promise<void> {
    console.log(`üîÑ Processing buffer ${buffer.id} with REAL OpenAI Whisper API (${buffer.duration.toFixed(1)}s)`);
    
    try {
      // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ –≤ WAV Blob
      const audioBlob = this.audioDataToWAV(buffer.audioData);
      
      // –°—Ç—Ä–æ–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç
      const contextPrompt = this.buildContextPrompt();
      
      // –†–ï–ê–õ–¨–ù–´–ô –≤—ã–∑–æ–≤ –∫ OpenAI Whisper API
      const result = await this.whisperApi.transcribe(audioBlob, {
        language: null, // –ê–≤—Ç–æ–¥–µ—Ç–µ–∫—Ü–∏—è RU/EN
        prompt: contextPrompt,
        temperature: 0.0,
        response_format: 'verbose_json'
      });

      // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –±—É—Ñ–µ—Ä
      buffer.transcription = {
        text: result.text,
        confidence: result.confidence,
        wordTimestamps: result.words || [],
        language: result.language,
        isDraft: false,
        processingTime: 0 // –ë—É–¥–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω–æ
      };
      
      // –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
      this.updateTranscriptHistory(result.text);
      
      // –£–≤–µ–¥–æ–º–ª—è–µ–º –æ –Ω–æ–≤–æ–º —Ç–µ–∫—Å—Ç–µ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å Deepgram API)
      if (this.onTranscriptCallback && result.text.trim()) {
        this.onTranscriptCallback({
          type: 'final',
          text: result.text,
          confidence: result.confidence,
          timestamp: Date.now(),
          language: result.language
        });
      }
      
      console.log(`‚úÖ REAL Whisper result: "${result.text.substring(0, 50)}..." (${(result.confidence * 100).toFixed(1)}%)`);
      
    } catch (error) {
      console.error(`‚ùå REAL Whisper API error for buffer ${buffer.id}:`, error);
      throw error;
    }
  }

  /**
   * –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç Float32Array –≤ WAV Blob
   */
  private audioDataToWAV(audioData: Float32Array): Blob {
    const sampleRate = 16000;
    const numChannels = 1;
    const bitsPerSample = 16;
    
    const buffer = new ArrayBuffer(44 + audioData.length * 2);
    const view = new DataView(buffer);
    
    // WAV –∑–∞–≥–æ–ª–æ–≤–æ–∫
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + audioData.length * 2, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, numChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * numChannels * bitsPerSample / 8, true);
    view.setUint16(32, numChannels * bitsPerSample / 8, true);
    view.setUint16(34, bitsPerSample, true);
    writeString(36, 'data');
    view.setUint32(40, audioData.length * 2, true);
    
    // –ê—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
    let offset = 44;
    for (let i = 0; i < audioData.length; i++) {
      const sample = Math.max(-1, Math.min(1, audioData[i]));
      view.setInt16(offset, sample * 0x7FFF, true);
      offset += 2;
    }
    
    return new Blob([buffer], { type: 'audio/wav' });
  }

  /**
   * –°—Ç—Ä–æ–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
   */
  private buildContextPrompt(): string {
    const openaiConfig = configService.getOpenAIConfig();
    let prompt = openaiConfig.prompt;
    
    if (this.transcriptHistory.length > 0) {
      const recentContext = this.transcriptHistory.slice(-2).join(' ');
      prompt += ` Previous context: "${recentContext}"`;
    }
    
    return prompt;
  }

  /**
   * –û–±–Ω–æ–≤–ª—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
   */
  private updateTranscriptHistory(newText: string): void {
    if (newText.trim().length > 0) {
      this.transcriptHistory.push(newText.trim());
      
      // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
      if (this.transcriptHistory.length > 5) {
        this.transcriptHistory.shift();
      }
    }
  }

  /**
   * –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç callbacks (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å Deepgram API)
   */
  setCallbacks(
    onTranscript: (event: TranscriptEvent) => void,
    onError: (error: string) => void
  ): void {
    this.onTranscriptCallback = onTranscript;
    this.onErrorCallback = onError;
  }

  /**
   * –û—Ç–∫–ª—é—á–∞–µ—Ç—Å—è –æ—Ç –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞
   */
  async disconnect(): Promise<void> {
    console.log('üîÑ Disconnecting REAL Whisper service...');
    
    this.isActive = false;
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
    if (this.processingInterval) {
      clearInterval(this.processingInterval);
      this.processingInterval = null;
    }
    
    if (this.bufferCheckInterval) {
      clearInterval(this.bufferCheckInterval);
      this.bufferCheckInterval = null;
    }
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—é
    if (this.bufferManager) {
      this.bufferManager.stopBuffering();
    }
    
    // –ó–∞–∫—Ä—ã–≤–∞–µ–º –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫
    if (this.stream) {
      this.stream.getTracks().forEach(track => track.stop());
      this.stream = null;
    }
    
    // –ó–∞–∫—Ä—ã–≤–∞–µ–º –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    if (this.audioContext) {
      await this.audioContext.close();
      this.audioContext = null;
    }
    
    console.log('‚úÖ REAL Whisper service disconnected');
  }

  /**
   * –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å Deepgram API)
   */
  getStats() {
    return {
      isActive: this.isActive,
      isInitialized: this.isInitialized,
      transcriptHistory: this.transcriptHistory.length,
      buffers: this.bufferManager ? {
        active: this.bufferManager.activeBuffers,
        currentDuration: this.bufferManager.currentBufferDuration,
        totalProcessed: this.bufferManager.totalProcessedTime
      } : null,
      vad: this.vadService ? this.vadService.getStats() : null
    };
  }
}

// –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º
export interface TranscriptEvent {
  type: 'partial' | 'final';
  text: string;
  confidence: number;
  timestamp: number;
  language?: string;
}

/**
 * –§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ù–ê–°–¢–û–Ø–©–ï–ì–û Whisper —Å–µ—Ä–≤–∏—Å–∞
 * –ó–∞–º–µ–Ω—è–µ—Ç createDeepgramService
 */
export const createRealWhisperService = (
  onTranscript: (event: TranscriptEvent) => void,
  onError: (error: string) => void
) => {
  const service = new RealWhisperReplacementService();
  service.setCallbacks(onTranscript, onError);
  
  return {
    connect: () => service.connect(),
    disconnect: () => service.disconnect(),
    getStats: () => service.getStats()
  };
};
