import React, { useState, useEffect, useRef } from "react";
import { TranscriptEvent } from "./services/deepgram";
import { ITranscriptionService } from "./types/ITranscriptionService";
import { TranscriptionServiceFactory } from "./services/transcription/TranscriptionServiceFactory";
import { createClaudeService, ClaudeAnalysisService, AnalysisContext, InsightResponse } from "./services/claude";
import { configService } from "./services/config";
import { LegacyInsight } from "./types/events";
import { StartScreen, RecordingScreen, WaveLoader } from "./components";
import { useAudioAnalyser } from "./hooks/useAudioAnalyser";
import { PostEditorConfig, CorrectionContext } from "./services/post-editor";
import { endCurrentSession } from "./services/transcript-logger";

// –¢–∏–ø—ã –¥–ª—è IPC
declare global {
  interface Window {
    require: any;
  }
}

export function App() {
  // –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ–∫–Ω–∞ –∏–∑ URL –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
  const urlParams = new URLSearchParams(window.location.search);
  const windowType = urlParams.get('window') || 'control'; // 'control' –∏–ª–∏ 'data'
  


  const [isVisible, setIsVisible] = useState(true);
  const [clickThrough, setClickThrough] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [hasPermission, setHasPermission] = useState<boolean | null>(null);
  const [transcript, setTranscript] = useState<string>('');
  const [partialTranscript, setPartialTranscript] = useState<string>('');
  const [insights, setInsights] = useState<Array<LegacyInsight>>([]);
  // Removed background blur functionality
  
  // mediaRecorderRef —É–¥–∞–ª–µ–Ω - –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–µ–Ω
  const streamRef = useRef<MediaStream | null>(null);
  const deepgramRef = useRef<ITranscriptionService | null>(null);
  const claudeRef = useRef<ClaudeAnalysisService | null>(null);
  const analysisContextRef = useRef<AnalysisContext | null>(null);
  // const ragServiceRef = useRef<RAGService | null>(null);
  const cleanupRef = useRef<(() => void) | null>(null);

  // Audio analysis hook
  const { audioLevel, initAudioAnalyser, stopAudioAnalyser } = useAudioAnalyser();

  // RAG system temporarily disabled

  // Cleanup audio analyser when recording stops
  useEffect(() => {
    if (!isRecording) {
      stopAudioAnalyser();
    }
  }, [isRecording, stopAudioAnalyser]);

  useEffect(() => {
    console.log('üöÄ App component mounted');
  }, []);

  useEffect(() => {
    const handleKeydown = (e: KeyboardEvent) => {
      if ((e.ctrlKey || e.metaKey) && e.key === "\\") {
        setIsVisible(!isVisible);
      }
      if ((e.ctrlKey || e.metaKey) && e.shiftKey && e.key === "T") {
        setClickThrough(!clickThrough);
      }
    };
    window.addEventListener("keydown", handleKeydown);
    return () => window.removeEventListener("keydown", handleKeydown);
  }, [isVisible, clickThrough]);

  useEffect(() => {
    console.log('üé§ Checking microphone permission...');
    checkMicPermission().catch(error => {
      console.warn('‚ö†Ô∏è Mic permission check failed:', error);
    });
  }, []);

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –æ–∫–Ω–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
  const sendToDataWindow = (type: 'transcript' | 'insights' | 'recording-state', data: any) => {
    try {
      if (window.require && windowType !== 'data') {
        const { ipcRenderer } = window.require('electron');
        console.log(`üì§ [IPC] Sending ${type} to data window:`, data);
        
        if (type === 'transcript') {
          ipcRenderer.invoke('send-transcript', data);
        } else if (type === 'insights') {
          ipcRenderer.invoke('send-insights', data);
        } else if (type === 'recording-state') {
          ipcRenderer.invoke('send-recording-state', data.isRecording);
        }
      }
    } catch (error) {
      console.warn(`‚ö†Ô∏è [IPC] Failed to send ${type}:`, error);
    }
  };

  // –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É –æ–∫–Ω–∞–º–∏ —á–µ—Ä–µ–∑ IPC
  useEffect(() => {
    if (windowType === 'data' && window.require) {
      const { ipcRenderer } = window.require('electron');
      
      // –°–ª—É—à–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
      const handleTranscriptUpdate = (event: any, data: any) => {
        console.log('üìù [DATA WINDOW] Transcript update received:', data);
        try {
          if (data.transcript !== undefined) setTranscript(data.transcript);
          if (data.partialTranscript !== undefined) setPartialTranscript(data.partialTranscript);
          console.log('‚úÖ [DATA WINDOW] State updated successfully');
        } catch (error) {
          console.error('‚ùå [DATA WINDOW] Failed to update transcript state:', error);
        }
      };

      // –°–ª—É—à–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤
      const handleInsightsUpdate = (event: any, insights: any) => {
        console.log('ü§ñ [DATA WINDOW] Insights update received:', insights);
        try {
          setInsights(insights || []);
          console.log('‚úÖ [DATA WINDOW] Insights updated successfully');
        } catch (error) {
          console.error('‚ùå [DATA WINDOW] Failed to update insights state:', error);
        }
      };

      // –°–ª—É—à–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –∑–∞–ø–∏—Å–∏
      const handleRecordingStateChange = (event: any, isRecordingState: boolean) => {
        console.log('üé§ [DATA WINDOW] Recording state change:', isRecordingState);
        try {
          setIsRecording(isRecordingState);
          console.log('‚úÖ [DATA WINDOW] Recording state updated successfully');
        } catch (error) {
          console.error('‚ùå [DATA WINDOW] Failed to update recording state:', error);
        }
      };

      ipcRenderer.on('transcript-update', handleTranscriptUpdate);
      ipcRenderer.on('insights-update', handleInsightsUpdate);
      ipcRenderer.on('recording-state-change', handleRecordingStateChange);

      return () => {
        ipcRenderer.removeAllListeners('transcript-update');
        ipcRenderer.removeAllListeners('insights-update');
        ipcRenderer.removeAllListeners('recording-state-change');
      };
    }
  }, [windowType]);

  const checkMicPermission = async () => {
    try {
      console.log('Checking microphone permission...');
      const audioConstraints = configService.getAudioConstraints();
      const stream = await navigator.mediaDevices.getUserMedia(audioConstraints);
      console.log('Microphone permission granted!');
      setHasPermission(true);
      stream.getTracks().forEach(track => track.stop());
    } catch (error) {
      console.error('Microphone permission denied:', error);
      setHasPermission(false);
    }
  };

  const connectToDeepgram = async (): Promise<() => void> => {
    console.log('üîó [DEEPGRAM] Starting Deepgram connection...');
    
    // –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ dev —Ä–µ–∂–∏–º–µ
    if (configService.isDevelopment) {
      console.log('üîß [DEEPGRAM] Development mode - logging config...');
      configService.logConfig();
    }
    
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Deepgram
    if (!configService.isDeepgramConfigured()) {
      throw new Error('‚ùå [DEEPGRAM] API key not configured! Please add DEEPGRAM_API_KEY to .env file');
    }
    
    console.log('‚úÖ [DEEPGRAM] API key configured, proceeding with real connection...');

    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º RAG —Å–µ—Ä–≤–∏—Å (–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω)
    console.log('üìù RAG service temporarily disabled for debugging');

    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Claude —Å–µ—Ä–≤–∏—Å –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
    if (configService.isClaudeConfigured()) {
      try {
        const claudeConfig = configService.getClaudeConfig();
        claudeRef.current = createClaudeService(claudeConfig); // RAG disabled
        analysisContextRef.current = new AnalysisContext();
        console.log('‚úÖ Claude service initialized with RAG support:', {
          model: claudeConfig.model,
          maxTokens: claudeConfig.maxTokens,
          temperature: claudeConfig.temperature,
          ragEnabled: false // temporarily disabled
        });
      } catch (error) {
        console.warn('‚ö†Ô∏è Claude service failed to initialize:', error);
      }
    } else {
      console.log('‚ö†Ô∏è Claude API key not configured, insights will be limited...');
    }

    try {
      console.log('üì° [DEEPGRAM] Connecting to real Deepgram...');
      
      const deepgramConfig = configService.getDeepgramConfig();
      console.log('üîß [DEEPGRAM] Using config:', {
        model: deepgramConfig.model,
        language: deepgramConfig.language,
        interim_results: deepgramConfig.interim_results,
        endpointing: deepgramConfig.endpointing
      });
      
      // –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ—Å—Ç—Ä–µ–¥–∞–∫—Ç–æ—Ä–∞
      let postEditorConfig: PostEditorConfig | undefined;
      let correctionContext: CorrectionContext | undefined;
      
      if (configService.isPostEditorConfigured()) {
        postEditorConfig = configService.getPostEditorConfig();
        correctionContext = {
          jobTerms: [], // –ë—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–æ –ø–æ–∑–∂–µ
          synonymDictionary: {} // –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –≤ post-editor.ts
        };
        console.log('üîß Post-editor enabled:', {
          model: postEditorConfig.model,
          timeout: postEditorConfig.timeoutMs
        });
      } else {
        console.log('‚ö†Ô∏è Post-editor not configured, skipping...');
      }
      
      // –°–æ–∑–¥–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–æ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å —á–µ—Ä–µ–∑ —Ñ–∞–±—Ä–∏–∫—É
      const deepgram = TranscriptionServiceFactory.create({
        provider: 'deepgram',
        apiKey: deepgramConfig.apiKey,
        onTranscript: async (event: TranscriptEvent) => {
          console.log('üìù [TRANSCRIPT] Received Deepgram event:', {
            type: event.type,
            text: event.text?.substring(0, 50) + '...',
            confidence: event.confidence,
            timestamp: new Date().toLocaleTimeString()
          });
          
          if (event.type === 'partial') {
            const newPartial = event.text;
            setPartialTranscript(newPartial);
            console.log('üîÑ [PARTIAL] Deepgram partial:', newPartial);
            
            // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –æ–∫–Ω–æ –¥–∞–Ω–Ω—ã—Ö
            sendToDataWindow('transcript', { transcript, partialTranscript: newPartial });
          } else if (event.type === 'final') {
            // –û–±–Ω–æ–≤–ª—è–µ–º –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
            const newTranscript = (transcript + ' ' + event.text).trim();
            setTranscript(newTranscript);
            setPartialTranscript('');
            
            // Full transcript accumulation removed - not used in current code
            
            console.log('‚úÖ [FINAL] Deepgram final result:', {
              text: event.text,
              confidence: event.confidence,
              length: event.text.length,
              wordCount: event.text.split(' ').length
            });
            
            // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –æ–∫–Ω–æ –¥–∞–Ω–Ω—ã—Ö
            sendToDataWindow('transcript', { transcript: newTranscript, partialTranscript: '' });
            
            // –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å –ø–æ–º–æ—â—å—é Claude –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            if (event.text.length > 10) {
              await analyzeWithClaude(event.text);
            }
          }
        },
        onError: (error: string) => {
          console.error('‚ùå [DEEPGRAM] Error:', error);
          setInsights(prev => [...prev.slice(-2), {
            id: Date.now().toString(),
            text: `Deepgram API error: ${error}`,
            type: 'risk'
          }]);
        },
        deepgramConfig,
        postEditorConfig,
        correctionContext
      });

      deepgramRef.current = deepgram;
      await deepgram.connect();
      
      return () => {
        deepgram.disconnect();
        deepgramRef.current = null;
        claudeRef.current = null;
        analysisContextRef.current = null;
      };
      
    } catch (error) {
      console.error('‚ùå [DEEPGRAM] Failed to connect to Deepgram:', error);
      throw error; // –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –¥–∞–ª—å—à–µ - –ù–ò–ö–ê–ö–ò–• –ú–û–ö–û–í!
    }
  };

  // –ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ —Å –ø–æ–º–æ—â—å—é Claude AI
  const analyzeWithClaude = async (newText: string): Promise<void> => {
    if (!claudeRef.current || !analysisContextRef.current) {
      console.log('‚ö†Ô∏è Claude not available, skipping analysis...');
      return;
    }

    try {
      // –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
      analysisContextRef.current.addTranscript(newText);
      const context = analysisContextRef.current.getContext();

      // –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
      const analysisRequest = {
        transcript: newText,
        contextWindow: context.contextWindow,
        entities: context.entities,
        topicHistory: context.topicHistory
      };

      console.log('ü§ñ Analyzing with Claude...', {
        text_length: newText.length,
        context_words: context.contextWindow.length,
        entities: context.entities.length
      });

      // –ü–æ–ª—É—á–∞–µ–º –∞–Ω–∞–ª–∏–∑ –æ—Ç Claude
      const analysis: InsightResponse = await claudeRef.current.analyzeTranscript(analysisRequest);

      // –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ø–∏–∫ –≤ –∏—Å—Ç–æ—Ä–∏—é
      analysisContextRef.current.addTopic(analysis.topic);

      // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç legacy insight –¥–ª—è UI
      const legacyInsight: LegacyInsight = {
        id: Date.now().toString(),
        text: analysis.note,
        type: analysis.type
      };

      // –û–±–Ω–æ–≤–ª—è–µ–º UI (–ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 insights)
      const newInsights = [...insights.slice(-2), legacyInsight];
      setInsights(newInsights);

      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –æ–∫–Ω–æ –¥–∞–Ω–Ω—ã—Ö
      sendToDataWindow('insights', newInsights);

      console.log('‚úÖ Claude analysis complete:', {
        topic: analysis.topic,
        depth_score: analysis.depth_score,
        type: analysis.type,
        confidence: analysis.confidence
      });

    } catch (error) {
      console.error('‚ùå Claude analysis failed:', error);
      // –ù–ò–ö–ê–ö–ò–• –ú–û–ö–û–í - –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É
    }
  };

  // –ú–û–ö –§–£–ù–ö–¶–ò–ò –£–î–ê–õ–ï–ù–´ - –ù–ò–ö–ê–ö–ò–• –§–ï–ô–ö–û–í!

  const startRecording = async () => {
    try {
      console.log('üé¨ [STEP 1] Starting recording...');
      
      // –°–ù–ê–ß–ê–õ–ê –º–µ–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ UI –¥–ª—è –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–π —Ä–µ–∞–∫—Ü–∏–∏
      setIsRecording(true);
      console.log('‚úÖ [STEP 2] UI state updated to recording');
      
      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ –æ–∫–Ω–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
      sendToDataWindow('recording-state', { isRecording: true });
      
      // –°–æ–∑–¥–∞–µ–º –æ–∫–Ω–æ —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏ –Ω–∞—á–∞–ª–µ –∑–∞–ø–∏—Å–∏
      if (window.require) {
        const { ipcRenderer } = window.require('electron');
        ipcRenderer.invoke('create-data-window'); // –£–±–∏—Ä–∞–µ–º await –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        console.log('üì± [STEP 3] Data window creation requested');
      }
      
      // –û—Å—Ç–∞–ª—å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è–µ–º –≤ —Ñ–æ–Ω–µ
      const audioConstraints = configService.getAudioConstraints();
      console.log('üé§ [STEP 4] Getting microphone access with constraints:', audioConstraints);
      
      const stream = await navigator.mediaDevices.getUserMedia(audioConstraints);
      console.log('‚úÖ [STEP 5] Got media stream:', {
        id: stream.id,
        active: stream.active,
        tracks: stream.getTracks().length
      });
      streamRef.current = stream;
      
      // Initialize audio analyser for SiriWave
      console.log('üéµ [STEP 6] Initializing audio analyser...');
      initAudioAnalyser(stream);
      
      // Connect to Deepgram (REAL ONLY - NO MOCKS!)
      console.log('üì° [STEP 7] Connecting to Deepgram...');
      try {
        cleanupRef.current = await connectToDeepgram();
        console.log('‚úÖ [STEP 8] Deepgram connection established');
      } catch (error) {
        console.error('‚ùå [DEEPGRAM] Connection failed:', error);
        setIsRecording(false);
        setHasPermission(false);
        const errorMessage = error instanceof Error ? error.message : String(error);
        throw new Error(`Deepgram connection failed: ${errorMessage}`);
      }
      
      // –ò—Å–ø–æ–ª—å–∑—É–µ–º AudioWorkletNode –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è PCM –¥–∞–Ω–Ω—ã—Ö
      const audioConfig = configService.audio;
      console.log('üîß [STEP 9] Creating AudioContext with config:', audioConfig);
      const audioContext = new AudioContext({ sampleRate: audioConfig.sampleRate });
      
      try {
        // –ó–∞–≥—Ä—É–∂–∞–µ–º Audio Worklet
        console.log('‚öôÔ∏è [STEP 10] Loading AudioWorklet module...');
        await audioContext.audioWorklet.addModule('/audioWorklet.js');
        console.log('‚úÖ [STEP 11] AudioWorklet module loaded');
        
        const source = audioContext.createMediaStreamSource(stream);
        const workletNode = new AudioWorkletNode(audioContext, 'pcm-processor');
        console.log('üîó [STEP 12] AudioWorklet nodes created');
        
        // –°—á–µ—Ç—á–∏–∫ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø–æ—Ç–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        let chunkCount = 0;
        let totalBytes = 0;
        
        // –°–ª—É—à–∞–µ–º PCM –¥–∞–Ω–Ω—ã–µ –æ—Ç worklet
        workletNode.port.onmessage = (event) => {
                  if (event.data.type === 'pcm-data' && deepgramRef.current) {
          chunkCount++;
          totalBytes += event.data.data.byteLength;
          
          // –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π 10-–π —á–∞–Ω–∫ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
          if (chunkCount % 10 === 0) {
            console.log(`üìä [AUDIO FLOW] Chunk #${chunkCount}: ${event.data.data.byteLength} bytes (total: ${(totalBytes/1024).toFixed(1)}KB)`);
          }
          
          deepgramRef.current.sendAudio(event.data.data);
        }
        };
        
        source.connect(workletNode);
        workletNode.connect(audioContext.destination);
        
        // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Å—ã–ª–∫–∏ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
        streamRef.current = stream;
        cleanupRef.current = () => {
          workletNode.disconnect();
          source.disconnect();
          audioContext.close();
          if (deepgramRef.current) {
            deepgramRef.current.disconnect();
            deepgramRef.current = null;
          }
          claudeRef.current = null;
          analysisContextRef.current = null;
        };
        
      } catch (error) {
        console.error('‚ùå AudioWorklet –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è:', error);
        throw new Error(`AudioWorklet not supported: ${error instanceof Error ? error.message : String(error)}`);
      }
      console.log('Recording started with Deepgram AudioWorklet!');
    } catch (error) {
      console.error('Error starting recording:', error);
      setHasPermission(false);
    }
  };

  // FALLBACK –§–£–ù–ö–¶–ò–ò –£–î–ê–õ–ï–ù–´ - –ù–ò–ö–ê–ö–ò–• –û–ë–•–û–î–ù–´–• –ü–£–¢–ï–ô!

  const stopRecording = () => {
    // –ó–∞–∫—Ä—ã–≤–∞–µ–º –æ–∫–Ω–æ —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –∑–∞–ø–∏—Å–∏
    if (window.require) {
      const { ipcRenderer } = window.require('electron');
      ipcRenderer.invoke('close-data-window');
    }
    
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    if (cleanupRef.current) {
      cleanupRef.current();
      cleanupRef.current = null;
    }
    
    // –ó–∞–≤–µ—Ä—à–∞–µ–º —Å–µ—Å—Å–∏—é –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    try {
      endCurrentSession();
      console.log('üìä Transcript session ended and saved to file');
    } catch (error) {
      console.warn('‚ö†Ô∏è Failed to end transcript session:', error);
    }
    
    // –û—á–∏—â–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–µ—Ä–≤–∏—Å—ã
            deepgramRef.current = null;
    claudeRef.current = null;
    if (analysisContextRef.current) {
      analysisContextRef.current.reset();
      analysisContextRef.current = null;
    }
    
    setIsRecording(false);
    setPartialTranscript('');
    // –û—Å—Ç–∞–≤–ª—è–µ–º transcript –∏ insights –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –ø–æ—Å–ª–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
    console.log('Recording stopped, session data preserved');
    
    // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ –æ–∫–Ω–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    sendToDataWindow('recording-state', { isRecording: false });
  };

  if (!isVisible) {
    return <div className="w-full h-full bg-transparent" />;
  }



  // –ï—Å–ª–∏ —ç—Ç–æ –æ–∫–Ω–æ –¥–∞–Ω–Ω—ã—Ö - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
  if (windowType === 'data') {

    return (
      <div className="data-window">
        <div className="data-window__header">
          <div className="header-left">
            <h2>üìù Live Transcript</h2>
            <div className={`data-window__status ${isRecording ? 'status--recording' : 'status--stopped'}`}>
              {isRecording ? (
                <>
                  <span className="status-indicator recording-pulse"></span>
                  üî¥ Recording
                </>
              ) : (
                <>
                  <span className="status-indicator stopped"></span>
                  ‚è∏Ô∏è Stopped
                </>
              )}
            </div>
          </div>
          
          {/* Header actions removed - functions don't exist in current code */}
        </div>
        
        <div className="data-window__content">
          <div className="transcript-section">
            <h3>Current Transcript:</h3>
            <div className="transcript-stats">
              <span className="word-count">{transcript ? transcript.split(' ').length : 0} words</span>
              <span className="char-count">{transcript ? transcript.length : 0} characters</span>
            </div>
            <div className="transcript-text">
              {transcript || 'No transcript yet...'}
            </div>
          </div>
          
          {partialTranscript && (
            <div className="partial-transcript-section animate-fade-in">
              <h3>üîÑ Live:</h3>
              <div className="partial-transcript-text">
                {partialTranscript}
              </div>
            </div>
          )}
          
          <div className="insights-section">
            <h3>AI Insights:</h3>
            <div className="insights-list">
              {insights.length > 0 ? (
                insights.map((insight, index) => (
                  <div key={insight.id} className="insight-item animate-fade-in" style={{ animationDelay: `${index * 0.1}s` }}>
                    <span className="insight-icon">ü§ñ</span>
                    <span className="insight-text">{insight.text}</span>
                  </div>
                ))
              ) : (
                <div className="insight-placeholder">Waiting for insights...</div>
              )}
            </div>
          </div>
        </div>
      </div>
    );
  }

  // –ï–¥–∏–Ω–∞—è –ø–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å –∞–Ω–∏–º–∞—Ü–∏–µ–π –º–µ–∂–¥—É —Å–æ—Å—Ç–æ—è–Ω–∏—è–º–∏
  return (
    <div className={`w-full h-full ${isVisible ? 'opacity-100' : 'opacity-0'} transition-opacity duration-300`} 
         style={{ pointerEvents: clickThrough ? 'none' : 'auto' }}>
      
      <div className="w-full h-full flex items-center justify-center">
        <div className={`control-panel ${isRecording ? 'control-panel--recording' : ''} transition-all duration-500 ease-in-out`}>
          <div className="control-panel__actions">
            {/* Start/Stop Button —Å –∞–Ω–∏–º–∞—Ü–∏–µ–π */}
            <div className="button-container">
              {!isRecording ? (
                <button
                  onClick={hasPermission ? startRecording : checkMicPermission}
                  className="start-button animate-fade-in"
                  style={{WebkitAppRegion: 'no-drag'} as any}
                >
                  <div className="start-button__icon">
                    <div className="start-button__icon-rect"></div>
                    <svg className="start-button__icon-svg" viewBox="0 0 8 10" fill="none">
                      <ellipse cx="4" cy="8" rx="4" ry="2" stroke="white" strokeWidth="1.4"/>
                    </svg>
                  </div>
                  <span>{hasPermission ? 'Start' : 'Allow Mic'}</span>
                </button>
              ) : (
                <button
                  onClick={stopRecording}
                  className="stop-button animate-fade-in"
                  style={{WebkitAppRegion: 'no-drag'} as any}
                >
                  <div className="stop-button__icon"></div>
                </button>
              )}
            </div>
            
            {/* Wave Loader —Å –∞–Ω–∏–º–∞—Ü–∏–µ–π –ø–æ—è–≤–ª–µ–Ω–∏—è/–∏—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏—è */}
            <div className={`wave-loader-wrapper transition-all duration-500 ease-in-out ${
              isRecording 
                ? 'opacity-100 translate-x-0 w-auto' 
                : 'opacity-0 -translate-x-4 w-0 overflow-hidden'
            }`}>
              <WaveLoader
                isActive={isRecording}
                audioLevel={audioLevel}
                partialTranscript={partialTranscript}
                width={20}
                height={15}
              />
            </div>
          </div>
          
          <div className="control-panel__separator"></div>
          
          <div 
            className="control-panel__drag-zone"
            style={{WebkitAppRegion: 'drag'} as any}
          >
            <div className="drag-dots">
              <div className="drag-dots__dot"></div>
              <div className="drag-dots__dot"></div>
              <div className="drag-dots__dot"></div>
              <div className="drag-dots__dot"></div>
            </div>
          </div>
        </div>
      </div>
      
      {/* Click-through –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä */}
      {clickThrough && (
        <div className="click-through-indicator">
          Click-through mode
        </div>
      )}
    </div>
  );
}
